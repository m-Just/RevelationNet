{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "TRAIN = 0\n",
    "EVAL  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "y_train = y_train.reshape([y_train.shape[0]])\n",
    "y_test = y_test.reshape([y_test.shape[0]])\n",
    "\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)\n",
    "flow = datagen.flow(x_train, y_train,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size = 1280).repeat()\n",
    "train = train.batch(128)\n",
    "train_itr = train.make_initializable_iterator()\n",
    "next_batch = train_itr.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = tf.Variable(tf.zeros([32,32,3]))\n",
    "y_= tf.placeholder(tf.float32,[1,10])\n",
    "# whether is training or not\n",
    "mode = tf.placeholder(tf.int32,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy   \n",
    "def ce(y_pred, labels):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = labels ,logits = y_pred))\n",
    "\n",
    "# accuracy    \n",
    "def acc(y_pred, labels):\n",
    "    correct_prediction =tf.equal(tf.argmax(y_pred,1), tf.argmax(labels,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction,tf.float32),0)\n",
    "\n",
    "def noisy_conv2d(inputs,filters,kernel_size,padding,strides,activation,name,scope_name = \"conv\", noise_on_kernel = True,noise_on_bias = True):\n",
    "    print(\"in shape:\", inputs.get_shape())\n",
    "    kernel_shape = [kernel_size,kernel_size,inputs.get_shape().as_list()[-1],filters]\n",
    "    print(\"kernel shape:\", kernel_shape)\n",
    "    bias_shape = [filters]\n",
    "    kernel = tf.Variable(np.random.normal(size = kernel_shape), dtype = tf.float32, name = name + \"/kernel\")\n",
    "    bias = tf.Variable(np.random.normal(size = bias_shape), dtype = tf.float32, name = name+\"/bias\")\n",
    "\n",
    "    kernel_noise = tf.random_normal(shape = kernel_shape, stddev= 0.5)\n",
    "    bias_noise = tf.random_normal(shape = bias_shape, stddev= 0.5)\n",
    "\n",
    "    if noise_on_kernel:\n",
    "        kernel = tf.multiply(1 + kernel_noise, kernel)\n",
    "    if noise_on_bias:\n",
    "        bias = tf.multiply(1 + bias_noise, bias)\n",
    "    output = activation(tf.nn.bias_add(tf.nn.conv2d(input = inputs ,filter = kernel,strides = [1, strides, strides, 1], padding = padding, name = name),bias))\n",
    "    print(\"out shape:\", output.get_shape())\n",
    "    return output\n",
    "    \n",
    "def noisy_dense(inputs,units,activation,name,scope_name = \"conv\", noise_on_kernel = True, noise_on_bias = True):\n",
    "    kernel_shape = inputs.get_shape().as_list()[1:] + [units]\n",
    "    bias_shape = [units]\n",
    "    kernel = tf.Variable(np.random.normal(size = kernel_shape), dtype = tf.float32, name = name +\"/kernel\")\n",
    "    bias = tf.Variable(np.random.normal(size = bias_shape), dtype = tf.float32, name = name + \"/bias\")\n",
    "\n",
    "    kernel_noise = tf.random_normal(shape = kernel_shape, stddev= 0.5)\n",
    "    bias_noise = tf.random_normal(shape = bias_shape, stddev= 0.5)\n",
    "\n",
    "    if noise_on_kernel:\n",
    "        kernel = tf.multiply(1 + kernel_noise, kernel)\n",
    "    if noise_on_bias:\n",
    "        bias = tf.multiply(1 + bias_noise, bias)\n",
    "    return activation(tf.nn.bias_add(tf.matmul(inputs,kernel),bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in shape: (1, 32, 32, 3)\n",
      "kernel shape: [3, 3, 3, 64]\n",
      "out shape: (1, 30, 30, 64)\n",
      "in shape: (1, 30, 30, 64)\n",
      "kernel shape: [3, 3, 64, 64]\n",
      "out shape: (1, 28, 28, 64)\n",
      "in shape: (1, 14, 14, 64)\n",
      "kernel shape: [3, 3, 64, 128]\n",
      "out shape: (1, 12, 12, 128)\n",
      "in shape: (1, 12, 12, 128)\n",
      "kernel shape: [3, 3, 128, 128]\n",
      "out shape: (1, 10, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"conv\") as scope:\n",
    "    prev_layer = tf.expand_dims(x, 0)\n",
    "    prev_layer = noisy_conv2d(\n",
    "        inputs = prev_layer,\n",
    "        filters = 64,\n",
    "        kernel_size = 3,\n",
    "        padding = 'VALID',\n",
    "        strides = 1,\n",
    "        activation =tf.nn.relu,\n",
    "        name = 'conv2d_1',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "    prev_layer = noisy_conv2d(\n",
    "        inputs = prev_layer,\n",
    "        filters = 64,\n",
    "        kernel_size = 3,\n",
    "        padding = 'VALID',\n",
    "        strides = 1,\n",
    "        activation =tf.nn.relu,\n",
    "        name = 'conv2d_2',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "    prev_layer = tf.layers.max_pooling2d(\n",
    "        inputs = prev_layer,\n",
    "        pool_size = 2,\n",
    "        strides = 2\n",
    "    )\n",
    "\n",
    "\n",
    "    prev_layer = noisy_conv2d(\n",
    "        inputs = prev_layer,\n",
    "        filters = 128,\n",
    "        kernel_size = 3,\n",
    "        padding = 'VALID',\n",
    "        strides = 1,\n",
    "        activation =tf.nn.relu,\n",
    "        name = 'conv2d_3',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "    prev_layer = noisy_conv2d(\n",
    "        inputs = prev_layer,\n",
    "        filters = 128,\n",
    "        kernel_size = 3,\n",
    "        padding = 'VALID',\n",
    "        strides = 1,\n",
    "        activation =tf.nn.relu,\n",
    "        name = 'conv2d_4',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "    prev_layer = tf.layers.max_pooling2d(\n",
    "        inputs = prev_layer,\n",
    "        pool_size = 2,\n",
    "        strides = 2\n",
    "    )\n",
    "\n",
    "    prev_layer = tf.contrib.layers.flatten(prev_layer)\n",
    "    flat = prev_layer\n",
    "\n",
    "    prev_layer = noisy_dense(\n",
    "        inputs = prev_layer,\n",
    "        units = 256,\n",
    "        activation = tf.nn.relu,\n",
    "        name = 'dense_1',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "\n",
    "\n",
    "    prev_layer = noisy_dense(\n",
    "        inputs = prev_layer,\n",
    "        units = 256,\n",
    "        activation = tf.nn.relu,\n",
    "        name = 'dense_2',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "\n",
    "    logits = noisy_dense(\n",
    "        inputs = prev_layer,\n",
    "        units = 10,\n",
    "        activation = lambda t:t,\n",
    "        name = 'dense_3',\n",
    "        scope_name = \"conv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self, imgsize, conv_input, logits, cls_no=10):\n",
    "        imgshape = (imgsize, imgsize, 3)\n",
    "        self.x = tf.placeholder(tf.float32, imgshape)\n",
    "        self.y_adv = tf.placeholder(tf.int32, ())\n",
    "        self.x_adv = conv_input\n",
    "\n",
    "        self.assign_op = tf.assign(self.x_adv, self.x)\n",
    "\n",
    "        self.lr = tf.placeholder(tf.float32, ())\n",
    "        labels = tf.one_hot(self.y_adv, cls_no)\n",
    "        self.loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=[labels])\n",
    "        self.optim_step = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss, var_list=[self.x_adv])\n",
    "\n",
    "        self.epsilon = tf.placeholder(tf.float32, ())\n",
    "        below = self.x - self.epsilon\n",
    "        above = self.x + self.epsilon\n",
    "        projected = tf.clip_by_value(tf.clip_by_value(self.x_adv, below, above), 0, 1)\n",
    "        with tf.control_dependencies([projected]):\n",
    "            self.project_step = tf.assign(self.x_adv, projected)\n",
    "\n",
    "    def generate(self, sess, image, target, eps_val=0.01, lr_val=1e-1, num_steps=100):\n",
    "        sess.run(self.assign_op, feed_dict={self.x: image})\n",
    "\n",
    "        for i in range(num_steps):\n",
    "            _, loss_val = sess.run([self.optim_step, self.loss], feed_dict={self.lr: lr_val, self.y_adv: target})\n",
    "            sess.run(self.project_step, feed_dict={self.x: image, self.epsilon: eps_val})\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('step %d, loss=%g' % (i+1, loss_val))\n",
    "\n",
    "        return sess.run(self.x_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-4b7dab3a8ff7>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = tf.nn.softmax(logits)\n",
    "loss=ce(logits, y_)\n",
    "accuracy=acc(pred, y_)\n",
    "\n",
    "theta_conv = tf.trainable_variables(\"conv\")\n",
    "conv_solver = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss = loss)\n",
    "\n",
    "fgsm_agent = Generator(32, x, logits)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_itr.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from noisy_pretrained/model\n",
      "step 10, loss=0.000504128\n",
      "step 20, loss=0.000352082\n",
      "step 30, loss=0.000394624\n",
      "step 40, loss=1.19209e-06\n",
      "step 50, loss=0\n",
      "step 60, loss=3.33785e-06\n",
      "step 70, loss=1.12056e-05\n",
      "step 80, loss=9.41749e-06\n",
      "step 90, loss=0.000103945\n",
      "step 100, loss=4.64915e-06\n",
      "step 10, loss=0.00400325\n",
      "step 20, loss=0.0118491\n",
      "step 30, loss=0.00162636\n",
      "step 40, loss=0.00148794\n",
      "step 50, loss=5.94837e-05\n",
      "step 60, loss=0.00108779\n",
      "step 70, loss=0\n",
      "step 80, loss=0.000122182\n",
      "step 90, loss=8.34465e-07\n",
      "step 100, loss=2.82522e-05\n",
      "step 10, loss=0.000200967\n",
      "step 20, loss=0.00344445\n",
      "step 30, loss=1.83581e-05\n",
      "step 40, loss=0.133586\n",
      "step 50, loss=0.000275812\n",
      "step 60, loss=0.00256935\n",
      "step 70, loss=0.00784175\n",
      "step 80, loss=0.0023622\n",
      "step 90, loss=7.78406e-05\n",
      "step 100, loss=0.00090296\n",
      "step 10, loss=8.4039e-05\n",
      "step 20, loss=0.025105\n",
      "step 30, loss=0.00521715\n",
      "step 40, loss=4.76837e-07\n",
      "step 50, loss=1.19209e-07\n",
      "step 60, loss=0.00122091\n",
      "step 70, loss=0\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=5.96046e-07\n",
      "step 10, loss=1.306\n",
      "step 20, loss=0.00494768\n",
      "step 30, loss=7.86778e-06\n",
      "step 40, loss=0.00017117\n",
      "step 50, loss=0.00275161\n",
      "step 60, loss=5.09011e-05\n",
      "step 70, loss=0.00055405\n",
      "step 80, loss=0.00062887\n",
      "step 90, loss=6.36557e-05\n",
      "step 100, loss=1.53779e-05\n",
      "step 10, loss=0.010856\n",
      "step 20, loss=1.19209e-07\n",
      "step 30, loss=0\n",
      "step 40, loss=0\n",
      "step 50, loss=0\n",
      "step 60, loss=3.9339e-06\n",
      "step 70, loss=0.000182016\n",
      "step 80, loss=1.19209e-07\n",
      "step 90, loss=2.38419e-07\n",
      "step 100, loss=0\n",
      "step 10, loss=0.00110208\n",
      "step 20, loss=0.000528792\n",
      "step 30, loss=0.00457407\n",
      "step 40, loss=3.06363e-05\n",
      "step 50, loss=0.000170336\n",
      "step 60, loss=0.00100848\n",
      "step 70, loss=0.000194531\n",
      "step 80, loss=7.15256e-07\n",
      "step 90, loss=0.000982279\n",
      "step 100, loss=2.26497e-06\n",
      "step 10, loss=0.00098216\n",
      "step 20, loss=0.00122591\n",
      "step 30, loss=0.0757712\n",
      "step 40, loss=4.05311e-06\n",
      "step 50, loss=0.000232669\n",
      "step 60, loss=2.26497e-06\n",
      "step 70, loss=1.06096e-05\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=5.74572e-05\n",
      "step 10, loss=0.00437197\n",
      "step 20, loss=0\n",
      "step 30, loss=9.91772e-05\n",
      "step 40, loss=0\n",
      "step 50, loss=0.00035387\n",
      "step 60, loss=5.56692e-05\n",
      "step 70, loss=1.21593e-05\n",
      "step 80, loss=1.19209e-07\n",
      "step 90, loss=0.00392892\n",
      "step 100, loss=2.86102e-06\n",
      "step 10, loss=0.209963\n",
      "step 20, loss=0.000415596\n",
      "step 30, loss=1.72852e-05\n",
      "step 40, loss=1.03712e-05\n",
      "step 50, loss=0.000727389\n",
      "step 60, loss=0.0421377\n",
      "step 70, loss=8.94066e-06\n",
      "step 80, loss=0.000310015\n",
      "step 90, loss=0.0108354\n",
      "step 100, loss=0.000500673\n",
      "step 10, loss=0.00219593\n",
      "step 20, loss=0.000217772\n",
      "step 30, loss=5.56692e-05\n",
      "step 40, loss=0.00140354\n",
      "step 50, loss=0.000172719\n",
      "step 60, loss=6.55649e-06\n",
      "step 70, loss=0.00021503\n",
      "step 80, loss=3.57628e-07\n",
      "step 90, loss=2.14576e-06\n",
      "step 100, loss=0.000191074\n",
      "step 10, loss=0.00377051\n",
      "step 20, loss=3.45706e-06\n",
      "step 30, loss=0.0171637\n",
      "step 40, loss=0.851379\n",
      "step 50, loss=3.57621e-05\n",
      "step 60, loss=0.000149835\n",
      "step 70, loss=2.25303e-05\n",
      "step 80, loss=5.96046e-07\n",
      "step 90, loss=5.38811e-05\n",
      "step 100, loss=3.57628e-07\n",
      "step 10, loss=1.76428e-05\n",
      "step 20, loss=0\n",
      "step 30, loss=5.96046e-07\n",
      "step 40, loss=3.21865e-06\n",
      "step 50, loss=1.69276e-05\n",
      "step 60, loss=4.17232e-06\n",
      "step 70, loss=0.00289034\n",
      "step 80, loss=0.00182426\n",
      "step 90, loss=1.78814e-06\n",
      "step 100, loss=0.00117102\n",
      "step 10, loss=0.0116387\n",
      "step 20, loss=0.0111385\n",
      "step 30, loss=3.36165e-05\n",
      "step 40, loss=1.19209e-06\n",
      "step 50, loss=2.38419e-07\n",
      "step 60, loss=1.19209e-06\n",
      "step 70, loss=0.0283428\n",
      "step 80, loss=1.54972e-06\n",
      "step 90, loss=0.0100591\n",
      "step 100, loss=0.000906176\n",
      "step 10, loss=0.00031228\n",
      "step 20, loss=1.19209e-07\n",
      "step 30, loss=0\n",
      "step 40, loss=6.35365e-05\n",
      "step 50, loss=3.57628e-07\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=0.000160204\n",
      "step 90, loss=2.71793e-05\n",
      "step 100, loss=0\n",
      "step 10, loss=0.00189589\n",
      "step 20, loss=3.17092e-05\n",
      "step 30, loss=0.000173792\n",
      "step 40, loss=5.72203e-06\n",
      "step 50, loss=0\n",
      "step 60, loss=0\n",
      "step 70, loss=1.19209e-07\n",
      "step 80, loss=0.000697489\n",
      "step 90, loss=0\n",
      "step 100, loss=6.01989e-05\n",
      "step 10, loss=0.000262941\n",
      "step 20, loss=0.000282248\n",
      "step 30, loss=5.2452e-06\n",
      "step 40, loss=3.57628e-07\n",
      "step 50, loss=4.76837e-07\n",
      "step 60, loss=9.05987e-06\n",
      "step 70, loss=1.43051e-06\n",
      "step 80, loss=0.000101919\n",
      "step 90, loss=6.42517e-05\n",
      "step 100, loss=0\n",
      "step 10, loss=0.00912673\n",
      "step 20, loss=2.22919e-05\n",
      "step 30, loss=6.07966e-06\n",
      "step 40, loss=0\n",
      "step 50, loss=5.48361e-06\n",
      "step 60, loss=2.62257e-05\n",
      "step 70, loss=8.18934e-05\n",
      "step 80, loss=8.34465e-07\n",
      "step 90, loss=4.37489e-05\n",
      "step 100, loss=2.38419e-07\n",
      "step 10, loss=2.74181e-06\n",
      "step 20, loss=0.00428805\n",
      "step 30, loss=8.96414e-05\n",
      "step 40, loss=1.19209e-07\n",
      "step 50, loss=9.9058e-05\n",
      "step 60, loss=1.23977e-05\n",
      "step 70, loss=0\n",
      "step 80, loss=5.24507e-05\n",
      "step 90, loss=1.64507e-05\n",
      "step 100, loss=5.00678e-06\n",
      "step 10, loss=0.000628512\n",
      "step 20, loss=5.25699e-05\n",
      "step 30, loss=1.39474e-05\n",
      "step 40, loss=0.000215388\n",
      "step 50, loss=8.54694e-05\n",
      "step 60, loss=3.45706e-06\n",
      "step 70, loss=6.56822e-05\n",
      "step 80, loss=0.000193577\n",
      "step 90, loss=0.000234457\n",
      "step 100, loss=2.38419e-07\n",
      "step 10, loss=0.0164749\n",
      "step 20, loss=0.0545279\n",
      "step 30, loss=0.0146274\n",
      "step 40, loss=0.00322525\n",
      "step 50, loss=0.000180109\n",
      "step 60, loss=1.19209e-07\n",
      "step 70, loss=1.19209e-07\n",
      "step 80, loss=5.96046e-07\n",
      "step 90, loss=5.3644e-06\n",
      "step 100, loss=8.91646e-05\n",
      "step 10, loss=0.0151718\n",
      "step 20, loss=0.000331109\n",
      "step 30, loss=0.0027144\n",
      "step 40, loss=0.154886\n",
      "step 50, loss=3.09944e-06\n",
      "step 60, loss=2.98023e-06\n",
      "step 70, loss=3.64774e-05\n",
      "step 80, loss=0.000273667\n",
      "step 90, loss=1.19209e-07\n",
      "step 100, loss=3.09944e-06\n",
      "step 10, loss=0.000195723\n",
      "step 20, loss=5.11395e-05\n",
      "step 30, loss=1.90733e-05\n",
      "step 40, loss=0\n",
      "step 50, loss=0.00913039\n",
      "step 60, loss=1.10864e-05\n",
      "step 70, loss=4.60137e-05\n",
      "step 80, loss=3.57628e-07\n",
      "step 90, loss=2.59873e-05\n",
      "step 100, loss=0\n",
      "step 10, loss=1.66893e-06\n",
      "step 20, loss=0\n",
      "step 30, loss=6.01989e-05\n",
      "step 40, loss=2.38419e-07\n",
      "step 50, loss=1.19209e-07\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=1.19209e-06\n",
      "step 10, loss=0.500212\n",
      "step 20, loss=4.07687e-05\n",
      "step 30, loss=6.09141e-05\n",
      "step 40, loss=0.00147187\n",
      "step 50, loss=0.00327337\n",
      "step 60, loss=0.00513852\n",
      "step 70, loss=0.0197347\n",
      "step 80, loss=0.00129235\n",
      "step 90, loss=0.00017856\n",
      "step 100, loss=0.00139235\n",
      "step 10, loss=0.00640175\n",
      "step 20, loss=0.00501458\n",
      "step 30, loss=0.00173787\n",
      "step 40, loss=0.00319756\n",
      "step 50, loss=0.0067131\n",
      "step 60, loss=0.00723149\n",
      "step 70, loss=6.55649e-06\n",
      "step 80, loss=0.000139942\n",
      "step 90, loss=0.000126354\n",
      "step 100, loss=0.000970846\n",
      "step 10, loss=1.19209e-07\n",
      "step 20, loss=0\n",
      "step 30, loss=5.96046e-07\n",
      "step 40, loss=1.19209e-07\n",
      "step 50, loss=0.000114673\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=0\n",
      "step 90, loss=5.45964e-05\n",
      "step 100, loss=0\n",
      "step 10, loss=0.00018297\n",
      "step 20, loss=0.0106914\n",
      "step 30, loss=1.91925e-05\n",
      "step 40, loss=0.000215388\n",
      "step 50, loss=0.000144114\n",
      "step 60, loss=0.00156209\n",
      "step 70, loss=0.000642927\n",
      "step 80, loss=1.19209e-07\n",
      "step 90, loss=0.000126711\n",
      "step 100, loss=0.000102157\n",
      "step 10, loss=0.00212622\n",
      "step 20, loss=0.000424533\n",
      "step 30, loss=9.8462e-05\n",
      "step 40, loss=0.000127069\n",
      "step 50, loss=2.38419e-07\n",
      "step 60, loss=0.000123612\n",
      "step 70, loss=0\n",
      "step 80, loss=4.76837e-07\n",
      "step 90, loss=3.18284e-05\n",
      "step 100, loss=2.63449e-05\n",
      "step 10, loss=4.16032e-05\n",
      "step 20, loss=0\n",
      "step 30, loss=5.48361e-06\n",
      "step 40, loss=1.60931e-05\n",
      "step 50, loss=3.45706e-06\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=3.57628e-07\n",
      "step 10, loss=0.00246483\n",
      "step 20, loss=0.000189644\n",
      "step 30, loss=0.000358994\n",
      "step 40, loss=0.0001136\n",
      "step 50, loss=4.76837e-07\n",
      "step 60, loss=6.79491e-06\n",
      "step 70, loss=6.80662e-05\n",
      "step 80, loss=0.000587529\n",
      "step 90, loss=1.19209e-07\n",
      "step 100, loss=0.00233068\n",
      "step 10, loss=0.00711455\n",
      "step 20, loss=7.15256e-07\n",
      "step 30, loss=0.0222817\n",
      "step 40, loss=0.000176891\n",
      "step 50, loss=0\n",
      "step 60, loss=0\n",
      "step 70, loss=0.000186068\n",
      "step 80, loss=0\n",
      "step 90, loss=1.66893e-06\n",
      "step 100, loss=2.02656e-06\n",
      "step 10, loss=2.51528e-05\n",
      "step 20, loss=3.57628e-07\n",
      "step 30, loss=3.2782e-05\n",
      "step 40, loss=0.000834474\n",
      "step 50, loss=0.000166879\n",
      "step 60, loss=1.3113e-06\n",
      "step 70, loss=7.25958e-05\n",
      "step 80, loss=0.000103468\n",
      "step 90, loss=0.00189316\n",
      "step 100, loss=1.40666e-05\n",
      "step 10, loss=0.4715\n",
      "step 20, loss=0.000547259\n",
      "step 30, loss=1.7166e-05\n",
      "step 40, loss=0.00393889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 50, loss=0.00553267\n",
      "step 60, loss=1.90735e-06\n",
      "step 70, loss=0.129755\n",
      "step 80, loss=3.57628e-07\n",
      "step 90, loss=4.17232e-06\n",
      "step 100, loss=0.00172621\n",
      "step 10, loss=4.13648e-05\n",
      "step 20, loss=0\n",
      "step 30, loss=9.67933e-05\n",
      "step 40, loss=0\n",
      "step 50, loss=0\n",
      "step 60, loss=0.000700586\n",
      "step 70, loss=0\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=0\n",
      "step 10, loss=2.74181e-06\n",
      "step 20, loss=2.45568e-05\n",
      "step 30, loss=6.32981e-05\n",
      "step 40, loss=0.000822325\n",
      "step 50, loss=7.62937e-06\n",
      "step 60, loss=1.19209e-07\n",
      "step 70, loss=6.91411e-06\n",
      "step 80, loss=4.52994e-06\n",
      "step 90, loss=2.38419e-07\n",
      "step 100, loss=3.9339e-06\n",
      "step 10, loss=0.000629465\n",
      "step 20, loss=0.0017863\n",
      "step 30, loss=1.90735e-06\n",
      "step 40, loss=5.66228e-05\n",
      "step 50, loss=0.000177606\n",
      "step 60, loss=0.000142445\n",
      "step 70, loss=0.0528207\n",
      "step 80, loss=9.13101e-05\n",
      "step 90, loss=6.43728e-06\n",
      "step 100, loss=9.79852e-05\n",
      "step 10, loss=0.000100608\n",
      "step 20, loss=0.0245015\n",
      "step 30, loss=0\n",
      "step 40, loss=3.45706e-06\n",
      "step 50, loss=1.13248e-05\n",
      "step 60, loss=1.3113e-06\n",
      "step 70, loss=2.38419e-07\n",
      "step 80, loss=0\n",
      "step 90, loss=7.15256e-07\n",
      "step 100, loss=0\n",
      "step 10, loss=0.074487\n",
      "step 20, loss=0\n",
      "step 30, loss=0\n",
      "step 40, loss=0\n",
      "step 50, loss=0\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=0\n",
      "step 10, loss=1.53779e-05\n",
      "step 20, loss=0.000103111\n",
      "step 30, loss=2.02656e-06\n",
      "step 40, loss=2.83714e-05\n",
      "step 50, loss=0.000384019\n",
      "step 60, loss=0.00143211\n",
      "step 70, loss=0.00110887\n",
      "step 80, loss=3.57628e-07\n",
      "step 90, loss=4.81594e-05\n",
      "step 100, loss=0.00134116\n",
      "step 10, loss=1.19209e-07\n",
      "step 20, loss=1.19209e-07\n",
      "step 30, loss=0.000231597\n",
      "step 40, loss=2.02656e-06\n",
      "step 50, loss=1.85965e-05\n",
      "step 60, loss=0\n",
      "step 70, loss=1.19209e-06\n",
      "step 80, loss=1.19209e-07\n",
      "step 90, loss=0\n",
      "step 100, loss=5.96046e-07\n",
      "step 10, loss=0.230957\n",
      "step 20, loss=0.0932532\n",
      "step 30, loss=0.000229928\n",
      "step 40, loss=0.00757299\n",
      "step 50, loss=0\n",
      "step 60, loss=5.91261e-05\n",
      "step 70, loss=4.76837e-07\n",
      "step 80, loss=4.7325e-05\n",
      "step 90, loss=1.19209e-07\n",
      "step 100, loss=0.000460876\n",
      "step 10, loss=0.00706176\n",
      "step 20, loss=0.000265206\n",
      "step 30, loss=0\n",
      "step 40, loss=0\n",
      "step 50, loss=3.57628e-07\n",
      "step 60, loss=0\n",
      "step 70, loss=5.38811e-05\n",
      "step 80, loss=1.19209e-07\n",
      "step 90, loss=0\n",
      "step 100, loss=1.74044e-05\n",
      "step 10, loss=0.00846063\n",
      "step 20, loss=0.000851031\n",
      "step 30, loss=1.04904e-05\n",
      "step 40, loss=0.00128163\n",
      "step 50, loss=0.00274115\n",
      "step 60, loss=0.00152293\n",
      "step 70, loss=1.54972e-06\n",
      "step 80, loss=2.38419e-07\n",
      "step 90, loss=1.19209e-07\n",
      "step 100, loss=5.2452e-06\n",
      "step 10, loss=1.74044e-05\n",
      "step 20, loss=8.34462e-06\n",
      "step 30, loss=0.0079657\n",
      "step 40, loss=1.45434e-05\n",
      "step 50, loss=9.20253e-05\n",
      "step 60, loss=4.29153e-06\n",
      "step 70, loss=0.00767379\n",
      "step 80, loss=1.19209e-07\n",
      "step 90, loss=2.14576e-06\n",
      "step 100, loss=0.000166641\n",
      "step 10, loss=0.0149774\n",
      "step 20, loss=0.00056251\n",
      "step 30, loss=0.000613025\n",
      "step 40, loss=0.018243\n",
      "step 50, loss=0.00823176\n",
      "step 60, loss=0.000852222\n",
      "step 70, loss=1.45434e-05\n",
      "step 80, loss=8.34465e-07\n",
      "step 90, loss=5.96046e-07\n",
      "step 100, loss=0.000112527\n",
      "step 10, loss=8.34465e-07\n",
      "step 20, loss=1.34706e-05\n",
      "step 30, loss=1.07288e-06\n",
      "step 40, loss=0\n",
      "step 50, loss=0\n",
      "step 60, loss=8.58303e-06\n",
      "step 70, loss=3.57628e-07\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=8.34465e-07\n",
      "step 10, loss=0.000118249\n",
      "step 20, loss=7.27174e-06\n",
      "step 30, loss=0.000744781\n",
      "step 40, loss=0.000221466\n",
      "step 50, loss=0.0266528\n",
      "step 60, loss=5.97221e-05\n",
      "step 70, loss=1.19209e-06\n",
      "step 80, loss=0\n",
      "step 90, loss=5.96046e-07\n",
      "step 100, loss=1.07288e-06\n",
      "step 10, loss=0.000747282\n",
      "step 20, loss=0.0568044\n",
      "step 30, loss=0.00159625\n",
      "step 40, loss=0.0125716\n",
      "step 50, loss=0.00639606\n",
      "step 60, loss=0.000997284\n",
      "step 70, loss=3.29012e-05\n",
      "step 80, loss=0.000397365\n",
      "step 90, loss=0\n",
      "step 100, loss=0.000290828\n",
      "step 10, loss=8.78534e-05\n",
      "step 20, loss=0.0232926\n",
      "step 30, loss=0\n",
      "step 40, loss=0\n",
      "step 50, loss=0.00013434\n",
      "step 60, loss=0\n",
      "step 70, loss=0.000107521\n",
      "step 80, loss=2.38419e-07\n",
      "step 90, loss=1.07288e-05\n",
      "step 100, loss=0\n",
      "step 10, loss=0.000902126\n",
      "step 20, loss=0.000306798\n",
      "step 30, loss=6.55649e-06\n",
      "step 40, loss=9.53674e-07\n",
      "step 50, loss=1.82389e-05\n",
      "step 60, loss=0.000215984\n",
      "step 70, loss=2.86102e-06\n",
      "step 80, loss=0.000369719\n",
      "step 90, loss=0.000708091\n",
      "step 100, loss=0.00218605\n",
      "step 10, loss=0.000371626\n",
      "step 20, loss=2.8729e-05\n",
      "step 30, loss=0\n",
      "step 40, loss=5.10203e-05\n",
      "step 50, loss=0.000241966\n",
      "step 60, loss=5.60282e-06\n",
      "step 70, loss=0.00061779\n",
      "step 80, loss=1.52587e-05\n",
      "step 90, loss=0.000186784\n",
      "step 100, loss=3.57628e-07\n",
      "step 10, loss=7.51016e-06\n",
      "step 20, loss=2.38419e-07\n",
      "step 30, loss=0.00472287\n",
      "step 40, loss=9.53674e-07\n",
      "step 50, loss=2.63449e-05\n",
      "step 60, loss=0\n",
      "step 70, loss=1.44242e-05\n",
      "step 80, loss=3.17092e-05\n",
      "step 90, loss=0.000122182\n",
      "step 100, loss=1.19209e-07\n",
      "step 10, loss=0.00669924\n",
      "step 20, loss=5.86492e-05\n",
      "step 30, loss=0.00186139\n",
      "step 40, loss=0.00186079\n",
      "step 50, loss=0.000206092\n",
      "step 60, loss=1.99078e-05\n",
      "step 70, loss=0\n",
      "step 80, loss=0.00268219\n",
      "step 90, loss=0\n",
      "step 100, loss=6.79491e-06\n",
      "step 10, loss=7.47414e-05\n",
      "step 20, loss=1.19209e-06\n",
      "step 30, loss=0.000910225\n",
      "step 40, loss=0.00043073\n",
      "step 50, loss=4.68482e-05\n",
      "step 60, loss=0.000190717\n",
      "step 70, loss=1.02519e-05\n",
      "step 80, loss=0.000246375\n",
      "step 90, loss=4.64915e-06\n",
      "step 100, loss=0.000258174\n",
      "step 10, loss=0.00767331\n",
      "step 20, loss=0.0036186\n",
      "step 30, loss=0.000188929\n",
      "step 40, loss=7.62937e-06\n",
      "step 50, loss=9.65549e-05\n",
      "step 60, loss=1.53779e-05\n",
      "step 70, loss=1.07288e-06\n",
      "step 80, loss=3.08747e-05\n",
      "step 90, loss=0.00037377\n",
      "step 100, loss=1.19209e-07\n",
      "step 10, loss=2.16959e-05\n",
      "step 20, loss=7.15256e-07\n",
      "step 30, loss=2.02656e-06\n",
      "step 40, loss=0\n",
      "step 50, loss=1.07288e-06\n",
      "step 60, loss=0.000178679\n",
      "step 70, loss=0\n",
      "step 80, loss=0\n",
      "step 90, loss=1.47818e-05\n",
      "step 100, loss=0\n",
      "step 10, loss=1.74044e-05\n",
      "step 20, loss=0.000752643\n",
      "step 30, loss=1.97885e-05\n",
      "step 40, loss=0.0105443\n",
      "step 50, loss=0.00737173\n",
      "step 60, loss=0.000141134\n",
      "step 70, loss=3.11131e-05\n",
      "step 80, loss=0.0036262\n",
      "step 90, loss=0.00108243\n",
      "step 100, loss=3.09944e-06\n",
      "step 10, loss=0.000242323\n",
      "step 20, loss=0.000134578\n",
      "step 30, loss=6.40133e-05\n",
      "step 40, loss=2.02656e-06\n",
      "step 50, loss=1.90735e-06\n",
      "step 60, loss=1.43051e-06\n",
      "step 70, loss=1.19209e-06\n",
      "step 80, loss=3.93383e-05\n",
      "step 90, loss=1.19209e-06\n",
      "step 100, loss=0\n",
      "step 10, loss=0.000253168\n",
      "step 20, loss=0.000918562\n",
      "step 30, loss=0.000501626\n",
      "step 40, loss=1.66892e-05\n",
      "step 50, loss=0.000919158\n",
      "step 60, loss=3.83847e-05\n",
      "step 70, loss=5.31659e-05\n",
      "step 80, loss=5.05435e-05\n",
      "step 90, loss=4.1484e-05\n",
      "step 100, loss=0.0011565\n",
      "step 10, loss=0.000815536\n",
      "step 20, loss=0.00355149\n",
      "step 30, loss=0.00094393\n",
      "step 40, loss=0.000239463\n",
      "step 50, loss=1.0848e-05\n",
      "step 60, loss=2.38418e-06\n",
      "step 70, loss=0.0105218\n",
      "step 80, loss=3.44509e-05\n",
      "step 90, loss=4.82786e-05\n",
      "step 100, loss=1.90735e-06\n",
      "step 10, loss=7.27174e-06\n",
      "step 20, loss=3.07555e-05\n",
      "step 30, loss=0.000388666\n",
      "step 40, loss=8.72574e-05\n",
      "step 50, loss=4.29153e-06\n",
      "step 60, loss=0.000131718\n",
      "step 70, loss=0\n",
      "step 80, loss=5.96046e-07\n",
      "step 90, loss=0.000161635\n",
      "step 100, loss=2.32455e-05\n",
      "step 10, loss=0.0669251\n",
      "step 20, loss=2.05038e-05\n",
      "step 30, loss=1.16824e-05\n",
      "step 40, loss=4.76837e-07\n",
      "step 50, loss=0.000494715\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=2.86102e-06\n",
      "step 90, loss=0\n",
      "step 100, loss=0\n",
      "step 10, loss=0.00944952\n",
      "step 20, loss=8.94066e-06\n",
      "step 30, loss=0.0242888\n",
      "step 40, loss=0.000564535\n",
      "step 50, loss=0\n",
      "step 60, loss=1.40666e-05\n",
      "step 70, loss=6.62782e-05\n",
      "step 80, loss=1.07288e-06\n",
      "step 90, loss=1.7166e-05\n",
      "step 100, loss=4.05311e-06\n",
      "step 10, loss=0.000874256\n",
      "step 20, loss=0.00633826\n",
      "step 30, loss=1.66892e-05\n",
      "step 40, loss=0.0102131\n",
      "step 50, loss=0\n",
      "step 60, loss=1.45434e-05\n",
      "step 70, loss=0.00133116\n",
      "step 80, loss=8.74958e-05\n",
      "step 90, loss=1.02519e-05\n",
      "step 100, loss=3.77886e-05\n",
      "step 10, loss=0.000111335\n",
      "step 20, loss=7.98699e-06\n",
      "step 30, loss=0.000982993\n",
      "step 40, loss=9.20253e-05\n",
      "step 50, loss=8.38006e-05\n",
      "step 60, loss=7.74857e-06\n",
      "step 70, loss=0.00210552\n",
      "step 80, loss=0.000537251\n",
      "step 90, loss=0.000266874\n",
      "step 100, loss=0.000554765\n",
      "step 10, loss=1.07288e-06\n",
      "step 20, loss=1.19209e-07\n",
      "step 30, loss=2.3484e-05\n",
      "step 40, loss=5.17355e-05\n",
      "step 50, loss=2.76562e-05\n",
      "step 60, loss=0.000112646\n",
      "step 70, loss=5.00678e-06\n",
      "step 80, loss=1.01327e-05\n",
      "step 90, loss=3.57628e-07\n",
      "step 100, loss=7.15256e-07\n",
      "step 10, loss=0\n",
      "step 20, loss=0.00020776\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 30, loss=0\n",
      "step 40, loss=9.53674e-07\n",
      "step 50, loss=0\n",
      "step 60, loss=0\n",
      "step 70, loss=1.19209e-07\n",
      "step 80, loss=1.3113e-06\n",
      "step 90, loss=0\n",
      "step 100, loss=0\n",
      "step 10, loss=2.8133e-05\n",
      "step 20, loss=0.00456256\n",
      "step 30, loss=1.54971e-05\n",
      "step 40, loss=2.98019e-05\n",
      "step 50, loss=0.0227812\n",
      "step 60, loss=9.59589e-05\n",
      "step 70, loss=0.000413332\n",
      "step 80, loss=2.26497e-06\n",
      "step 90, loss=2.14576e-06\n",
      "step 100, loss=2.38418e-06\n",
      "step 10, loss=0.0139202\n",
      "step 20, loss=0.00160494\n",
      "step 30, loss=0.00207792\n",
      "step 40, loss=0.000101204\n",
      "step 50, loss=3.2782e-05\n",
      "step 60, loss=6.84238e-05\n",
      "step 70, loss=3.2186e-05\n",
      "step 80, loss=0.00149996\n",
      "step 90, loss=0.00279227\n",
      "step 100, loss=1.19209e-07\n",
      "step 10, loss=1.90735e-06\n",
      "step 20, loss=1.90733e-05\n",
      "step 30, loss=2.6226e-06\n",
      "step 40, loss=5.28083e-05\n",
      "step 50, loss=0.00036388\n",
      "step 60, loss=1.19209e-07\n",
      "step 70, loss=0.000837929\n",
      "step 80, loss=0\n",
      "step 90, loss=2.45568e-05\n",
      "step 100, loss=0.000212051\n",
      "step 10, loss=7.70062e-05\n",
      "step 20, loss=1.19209e-07\n",
      "step 30, loss=0.00033528\n",
      "step 40, loss=3.33785e-06\n",
      "step 50, loss=9.59589e-05\n",
      "step 60, loss=2.86098e-05\n",
      "step 70, loss=1.43051e-06\n",
      "step 80, loss=0\n",
      "step 90, loss=8.94066e-06\n",
      "step 100, loss=0\n",
      "step 10, loss=2.3484e-05\n",
      "step 20, loss=0.00012981\n",
      "step 30, loss=0.000396054\n",
      "step 40, loss=6.42517e-05\n",
      "step 50, loss=2.50339e-06\n",
      "step 60, loss=1.83581e-05\n",
      "step 70, loss=5.96045e-06\n",
      "step 80, loss=7.27174e-06\n",
      "step 90, loss=0\n",
      "step 100, loss=0\n",
      "step 10, loss=9.22637e-05\n",
      "step 20, loss=0.00533099\n",
      "step 30, loss=0\n",
      "step 40, loss=8.1062e-06\n",
      "step 50, loss=1.19209e-07\n",
      "step 60, loss=3.57628e-07\n",
      "step 70, loss=0\n",
      "step 80, loss=1.31129e-05\n",
      "step 90, loss=0\n",
      "step 100, loss=3.57628e-07\n",
      "step 10, loss=0.000622198\n",
      "step 20, loss=1.19209e-07\n",
      "step 30, loss=9.0595e-05\n",
      "step 40, loss=0.0102\n",
      "step 50, loss=3.21865e-06\n",
      "step 60, loss=2.38419e-07\n",
      "step 70, loss=1.02519e-05\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=0.00248861\n",
      "step 10, loss=0.00644379\n",
      "step 20, loss=0.00619811\n",
      "step 30, loss=4.41073e-06\n",
      "step 40, loss=4.17232e-06\n",
      "step 50, loss=2.50339e-06\n",
      "step 60, loss=0.0026118\n",
      "step 70, loss=0.000295476\n",
      "step 80, loss=0.00013434\n",
      "step 90, loss=3.79078e-05\n",
      "step 100, loss=2.38419e-07\n",
      "step 10, loss=0.00096108\n",
      "step 20, loss=2.74181e-06\n",
      "step 30, loss=1.95501e-05\n",
      "step 40, loss=1.3709e-05\n",
      "step 50, loss=1.43051e-06\n",
      "step 60, loss=2.14576e-06\n",
      "step 70, loss=0\n",
      "step 80, loss=1.02519e-05\n",
      "step 90, loss=0.00252108\n",
      "step 100, loss=0\n",
      "step 10, loss=0.0023471\n",
      "step 20, loss=0.000237675\n",
      "step 30, loss=3.57628e-07\n",
      "step 40, loss=1.27553e-05\n",
      "step 50, loss=0.00106493\n",
      "step 60, loss=0.00409906\n",
      "step 70, loss=0.000315021\n",
      "step 80, loss=3.60006e-05\n",
      "step 90, loss=3.81469e-06\n",
      "step 100, loss=0.000123255\n",
      "step 10, loss=1.51395e-05\n",
      "step 20, loss=2.55105e-05\n",
      "step 30, loss=1.19209e-06\n",
      "step 40, loss=4.74442e-05\n",
      "step 50, loss=1.19209e-06\n",
      "step 60, loss=0.000206568\n",
      "step 70, loss=1.50203e-05\n",
      "step 80, loss=2.38419e-07\n",
      "step 90, loss=0.000560842\n",
      "step 100, loss=3.21865e-06\n",
      "step 10, loss=1.031\n",
      "step 20, loss=0.030424\n",
      "step 30, loss=0.0789967\n",
      "step 40, loss=0.000166641\n",
      "step 50, loss=0.0168894\n",
      "step 60, loss=0.0116509\n",
      "step 70, loss=0.00193183\n",
      "step 80, loss=0.0423506\n",
      "step 90, loss=0.00535625\n",
      "step 100, loss=9.53674e-07\n",
      "step 10, loss=0\n",
      "step 20, loss=5.96046e-07\n",
      "step 30, loss=5.2452e-06\n",
      "step 40, loss=0\n",
      "step 50, loss=0\n",
      "step 60, loss=0.00027462\n",
      "step 70, loss=4.64915e-06\n",
      "step 80, loss=0\n",
      "step 90, loss=3.00403e-05\n",
      "step 100, loss=4.76836e-06\n",
      "step 10, loss=0.000506273\n",
      "step 20, loss=0.00336901\n",
      "step 30, loss=4.17224e-05\n",
      "step 40, loss=0.016463\n",
      "step 50, loss=0.000208237\n",
      "step 60, loss=0.00117733\n",
      "step 70, loss=1.29937e-05\n",
      "step 80, loss=0.000102992\n",
      "step 90, loss=2.18151e-05\n",
      "step 100, loss=2.8133e-05\n",
      "step 10, loss=0.00830884\n",
      "step 20, loss=3.81469e-06\n",
      "step 30, loss=0\n",
      "step 40, loss=0\n",
      "step 50, loss=0\n",
      "step 60, loss=0.000142683\n",
      "step 70, loss=0\n",
      "step 80, loss=0.000372579\n",
      "step 90, loss=0\n",
      "step 100, loss=0.00578776\n",
      "step 10, loss=0.300538\n",
      "step 20, loss=0.00136378\n",
      "step 30, loss=0.000598132\n",
      "step 40, loss=0.00213431\n",
      "step 50, loss=1.13248e-05\n",
      "step 60, loss=0\n",
      "step 70, loss=1.19209e-07\n",
      "step 80, loss=0.00753194\n",
      "step 90, loss=0.000256982\n",
      "step 100, loss=2.47952e-05\n",
      "step 10, loss=0.000499243\n",
      "step 20, loss=2.74181e-06\n",
      "step 30, loss=0.00547197\n",
      "step 40, loss=2.38419e-07\n",
      "step 50, loss=1.3709e-05\n",
      "step 60, loss=2.50339e-06\n",
      "step 70, loss=0.00100526\n",
      "step 80, loss=1.43051e-06\n",
      "step 90, loss=9.9654e-05\n",
      "step 100, loss=0.0322643\n",
      "step 10, loss=0.020054\n",
      "step 20, loss=1.78814e-06\n",
      "step 30, loss=7.15256e-07\n",
      "step 40, loss=0.00102896\n",
      "step 50, loss=1.07288e-06\n",
      "step 60, loss=0.0018972\n",
      "step 70, loss=7.15256e-07\n",
      "step 80, loss=0.000154245\n",
      "step 90, loss=5.12599e-06\n",
      "step 100, loss=3.57627e-06\n",
      "step 10, loss=0.00027462\n",
      "step 20, loss=0.000194173\n",
      "step 30, loss=0.00243724\n",
      "step 40, loss=0.000174388\n",
      "step 50, loss=0\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=2.86098e-05\n",
      "step 90, loss=2.0027e-05\n",
      "step 100, loss=4.88757e-06\n",
      "step 10, loss=3.57628e-07\n",
      "step 20, loss=0\n",
      "step 30, loss=4.64915e-06\n",
      "step 40, loss=5.96046e-07\n",
      "step 50, loss=4.29153e-06\n",
      "step 60, loss=5.96046e-07\n",
      "step 70, loss=2.26497e-06\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=0\n",
      "step 10, loss=0.000670447\n",
      "step 20, loss=1.47818e-05\n",
      "step 30, loss=5.96046e-07\n",
      "step 40, loss=1.19209e-07\n",
      "step 50, loss=1.54972e-06\n",
      "step 60, loss=0\n",
      "step 70, loss=2.0027e-05\n",
      "step 80, loss=5.17355e-05\n",
      "step 90, loss=0\n",
      "step 100, loss=0\n",
      "step 10, loss=2.50339e-06\n",
      "step 20, loss=0.000105256\n",
      "step 30, loss=0.000901769\n",
      "step 40, loss=4.76836e-06\n",
      "step 50, loss=0.00020192\n",
      "step 60, loss=8.46382e-06\n",
      "step 70, loss=1.35898e-05\n",
      "step 80, loss=2.1219e-05\n",
      "step 90, loss=0.000315974\n",
      "step 100, loss=7.27174e-06\n",
      "step 10, loss=0.0679749\n",
      "step 20, loss=0.00540889\n",
      "step 30, loss=4.31528e-05\n",
      "step 40, loss=0.00102801\n",
      "step 50, loss=9.29828e-06\n",
      "step 60, loss=0.00196371\n",
      "step 70, loss=4.6729e-05\n",
      "step 80, loss=0\n",
      "step 90, loss=2.62257e-05\n",
      "step 100, loss=0.000191789\n",
      "step 10, loss=1.3113e-06\n",
      "step 20, loss=0.000921183\n",
      "step 30, loss=0.0120133\n",
      "step 40, loss=0.00306803\n",
      "step 50, loss=8.29662e-05\n",
      "step 60, loss=1.78814e-06\n",
      "step 70, loss=0\n",
      "step 80, loss=0.00378428\n",
      "step 90, loss=2.38419e-07\n",
      "step 100, loss=5.56692e-05\n",
      "step 10, loss=1.99078e-05\n",
      "step 20, loss=2.45568e-05\n",
      "step 30, loss=8.34465e-07\n",
      "step 40, loss=0.000129453\n",
      "step 50, loss=1.19209e-07\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=2.38419e-07\n",
      "step 90, loss=0.000586933\n",
      "step 100, loss=0\n",
      "step 10, loss=1.23977e-05\n",
      "step 20, loss=1.19209e-07\n",
      "step 30, loss=1.19209e-07\n",
      "step 40, loss=5.00678e-06\n",
      "step 50, loss=1.0848e-05\n",
      "step 60, loss=4.17232e-06\n",
      "step 70, loss=4.05311e-06\n",
      "step 80, loss=8.96414e-05\n",
      "step 90, loss=0\n",
      "step 100, loss=0\n",
      "step 10, loss=0.0130523\n",
      "step 20, loss=4.23184e-05\n",
      "step 30, loss=0\n",
      "step 40, loss=0\n",
      "step 50, loss=0\n",
      "step 60, loss=0.00159363\n",
      "step 70, loss=5.72203e-06\n",
      "step 80, loss=0\n",
      "step 90, loss=0\n",
      "step 100, loss=4.24376e-05\n",
      "step 10, loss=0.0585595\n",
      "step 20, loss=0.000148285\n",
      "step 30, loss=1.19209e-07\n",
      "step 40, loss=0.000683313\n",
      "step 50, loss=0.0173583\n",
      "step 60, loss=1.07288e-05\n",
      "step 70, loss=0.00356051\n",
      "step 80, loss=2.26497e-06\n",
      "step 90, loss=8.22541e-06\n",
      "step 100, loss=1.19209e-07\n",
      "step 10, loss=0.00049686\n",
      "step 20, loss=0.00115054\n",
      "step 30, loss=0.00188911\n",
      "step 40, loss=3.44509e-05\n",
      "step 50, loss=3.57628e-07\n",
      "step 60, loss=0\n",
      "step 70, loss=0\n",
      "step 80, loss=2.38419e-07\n",
      "step 90, loss=2.03846e-05\n",
      "step 100, loss=0\n",
      "step 10, loss=0\n",
      "step 20, loss=0.026419\n",
      "step 30, loss=0.0777855\n",
      "step 40, loss=0.000178202\n",
      "step 50, loss=0.000132433\n",
      "step 60, loss=0.0553149\n",
      "step 70, loss=0.000110382\n",
      "step 80, loss=0.000144948\n",
      "step 90, loss=0.00251905\n",
      "step 100, loss=0.00939921\n",
      "step 10, loss=0.0319024\n",
      "step 20, loss=0.0288065\n",
      "step 30, loss=0.00925288\n",
      "step 40, loss=4.76836e-06\n",
      "step 50, loss=1.19209e-07\n",
      "step 60, loss=0.000728938\n",
      "step 70, loss=0.00137366\n",
      "step 80, loss=6.19886e-06\n",
      "step 90, loss=0.00489893\n",
      "step 100, loss=3.46893e-05\n",
      "step 10, loss=0.000103588\n",
      "step 20, loss=3.21865e-06\n",
      "step 30, loss=5.96046e-07\n",
      "step 40, loss=5.10203e-05\n",
      "step 50, loss=0.00333301\n",
      "step 60, loss=0\n",
      "step 70, loss=6.99734e-05\n",
      "step 80, loss=0.00012099\n",
      "step 90, loss=6.96158e-05\n",
      "step 100, loss=1.19209e-06\n",
      "(100, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list = theta_conv)\n",
    "saver.restore(sess,\"noisy_pretrained/model\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "adv_imgs = None\n",
    "y_real = []\n",
    "for each in zip(x_test,y_test):\n",
    "    if sess.run(accuracy, feed_dict={x: each[0],y_: [each[1]],mode: EVAL}) == 1 and np.argmax(each[1])!=target_label:\n",
    "        adv_img = np.expand_dims(fgsm_agent.generate(sess,each[0],target_label, eps_val=0.3), axis=0)\n",
    "        if adv_imgs is None:\n",
    "            adv_imgs = adv_img\n",
    "        else:\n",
    "            adv_imgs = np.concatenate((adv_imgs,adv_img),axis = 0)\n",
    "        y_real.append(each[1])\n",
    "        i+= 1\n",
    "    if i >= 100:\n",
    "        break\n",
    "print(adv_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on test set: 0.0\n"
     ]
    }
   ],
   "source": [
    "FINAL_ACC=0.\n",
    "for i in range(0,100):\n",
    "    FINAL_ACC+=1/100*sess.run(accuracy, feed_dict={x: adv_imgs[i], y_: y_real[i:i+1], mode: EVAL})   \n",
    "print(\"Final accuracy on test set:\", FINAL_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on test set: 1.0000000000000007\n"
     ]
    }
   ],
   "source": [
    "FINAL_ACC=0.\n",
    "for i in range(0,100):\n",
    "    FINAL_ACC+=1/100*sess.run(accuracy, feed_dict={x: adv_imgs[i], y_: [np.eye(10)[target_label]], mode: EVAL})   \n",
    "print(\"Final accuracy on test set:\", FINAL_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3200)\n"
     ]
    }
   ],
   "source": [
    "X = None\n",
    "for i in range(0,1):\n",
    "    if i == 0:\n",
    "        X = sess.run(flat, feed_dict={x: x_test[i*1000:(i+1)*1000], y_: y_test[i*1000:(i+1)*1000], mode: EVAL}) \n",
    "    else:\n",
    "        X = np.concatenate((X,sess.run(flat, feed_dict={x: x_test[i*1000:(i+1)*1000], y_: y_test[i*1000:(i+1)*1000], mode: EVAL})), axis = 0)\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff160e89748>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "colors = [i*25 for i in np.argmax(y_test[0:1000], axis = 1)]\n",
    "\n",
    "embedding = TSNE(n_components=2).fit_transform(X)\n",
    "plt.scatter(embedding[:,0],embedding[:,1], c = colors )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(2, 2)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for each in zip(np.array([1,2,3]),np.array([1,2,3])):\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 4 7 1 9 8 3 0 2 5]\n"
     ]
    }
   ],
   "source": [
    "targeted_label = np.array([i for i in range(10)])\n",
    "np.random.shuffle(targeted_label)\n",
    "print(targeted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
