{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "\n",
    "TRAIN = 0\n",
    "EVAL  = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "x_train = x_train/255\n",
    "x_test = x_test/255\n",
    "\n",
    "y_train = y_train.reshape([y_train.shape[0]])\n",
    "y_test = y_test.reshape([y_test.shape[0]])\n",
    "\n",
    "y_train = np.eye(10)[y_train]\n",
    "y_test = np.eye(10)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(x_train)\n",
    "flow = datagen.flow(x_train, y_train,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(buffer_size = 1280).repeat()\n",
    "train = train.batch(128)\n",
    "train_itr = train.make_initializable_iterator()\n",
    "next_batch = train_itr.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "x = tf.Variable(tf.zeros([32,32,3]))\n",
    "y_= tf.placeholder(tf.float32,[1,10])\n",
    "# whether is training or not\n",
    "mode = tf.placeholder(tf.int32,[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cross_entropy   \n",
    "def ce(y_pred, labels):\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels = labels ,logits = y_pred))\n",
    "\n",
    "# accuracy    \n",
    "def acc(y_pred, labels):\n",
    "    correct_prediction =tf.equal(tf.argmax(y_pred,1), tf.argmax(labels,1))\n",
    "    return tf.reduce_mean(tf.cast(correct_prediction,tf.float32),0)\n",
    "\n",
    "def noisy_conv2d(inputs,filters,kernel_size,padding,strides,activation,name,scope_name = \"conv\", noise_on_kernel = True,noise_on_bias = True):\n",
    "    print(\"in shape:\", inputs.get_shape())\n",
    "    kernel_shape = [kernel_size,kernel_size,inputs.get_shape().as_list()[-1],filters]\n",
    "    print(\"kernel shape:\", kernel_shape)\n",
    "    bias_shape = [filters]\n",
    "    kernel = tf.Variable(np.random.normal(size = kernel_shape), dtype = tf.float32, name = name + \"/kernel\")\n",
    "    bias = tf.Variable(np.random.normal(size = bias_shape), dtype = tf.float32, name = name+\"/bias\")\n",
    "\n",
    "    kernel_noise = tf.random_normal(shape = kernel_shape, stddev= 0)\n",
    "    bias_noise = tf.random_normal(shape = bias_shape, stddev= 0)\n",
    "\n",
    "    if noise_on_kernel:\n",
    "        kernel = tf.multiply(1 + kernel_noise, kernel)\n",
    "    if noise_on_bias:\n",
    "        bias = tf.multiply(1 + bias_noise, bias)\n",
    "    output = activation(tf.nn.bias_add(tf.nn.conv2d(input = inputs ,filter = kernel,strides = [1, strides, strides, 1], padding = padding, name = name),bias))\n",
    "    print(\"out shape:\", output.get_shape())\n",
    "    return output\n",
    "    \n",
    "def noisy_dense(inputs,units,activation,name,scope_name = \"conv\", noise_on_kernel = True, noise_on_bias = True):\n",
    "    kernel_shape = inputs.get_shape().as_list()[1:] + [units]\n",
    "    bias_shape = [units]\n",
    "    kernel = tf.Variable(np.random.normal(size = kernel_shape), dtype = tf.float32, name = name +\"/kernel\")\n",
    "    bias = tf.Variable(np.random.normal(size = bias_shape), dtype = tf.float32, name = name + \"/bias\")\n",
    "\n",
    "    kernel_noise = tf.random_normal(shape = kernel_shape, stddev= 0)\n",
    "    bias_noise = tf.random_normal(shape = bias_shape, stddev= 0)\n",
    "\n",
    "    if noise_on_kernel:\n",
    "        kernel = tf.multiply(1 + kernel_noise, kernel)\n",
    "    if noise_on_bias:\n",
    "        bias = tf.multiply(1 + bias_noise, bias)\n",
    "    return activation(tf.nn.bias_add(tf.matmul(inputs,kernel),bias))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in shape: (1, 32, 32, 3)\n",
      "kernel shape: [3, 3, 3, 64]\n",
      "out shape: (1, 30, 30, 64)\n",
      "in shape: (1, 30, 30, 64)\n",
      "kernel shape: [3, 3, 64, 64]\n",
      "out shape: (1, 28, 28, 64)\n",
      "in shape: (1, 14, 14, 64)\n",
      "kernel shape: [3, 3, 64, 128]\n",
      "out shape: (1, 12, 12, 128)\n",
      "in shape: (1, 12, 12, 128)\n",
      "kernel shape: [3, 3, 128, 128]\n",
      "out shape: (1, 10, 10, 128)\n"
     ]
    }
   ],
   "source": [
    "with tf.variable_scope(\"conv\") as scope:\n",
    "    prev_layer = tf.expand_dims(x, 0)\n",
    "    prev_layer = noisy_conv2d(\n",
    "        inputs = prev_layer,\n",
    "        filters = 64,\n",
    "        kernel_size = 3,\n",
    "        padding = 'VALID',\n",
    "        strides = 1,\n",
    "        activation =tf.nn.relu,\n",
    "        name = 'conv2d_1',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "    prev_layer = noisy_conv2d(\n",
    "        inputs = prev_layer,\n",
    "        filters = 64,\n",
    "        kernel_size = 3,\n",
    "        padding = 'VALID',\n",
    "        strides = 1,\n",
    "        activation =tf.nn.relu,\n",
    "        name = 'conv2d_2',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "    prev_layer = tf.layers.max_pooling2d(\n",
    "        inputs = prev_layer,\n",
    "        pool_size = 2,\n",
    "        strides = 2\n",
    "    )\n",
    "\n",
    "\n",
    "    prev_layer = noisy_conv2d(\n",
    "        inputs = prev_layer,\n",
    "        filters = 128,\n",
    "        kernel_size = 3,\n",
    "        padding = 'VALID',\n",
    "        strides = 1,\n",
    "        activation =tf.nn.relu,\n",
    "        name = 'conv2d_3',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "    prev_layer = noisy_conv2d(\n",
    "        inputs = prev_layer,\n",
    "        filters = 128,\n",
    "        kernel_size = 3,\n",
    "        padding = 'VALID',\n",
    "        strides = 1,\n",
    "        activation =tf.nn.relu,\n",
    "        name = 'conv2d_4',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "    prev_layer = tf.layers.max_pooling2d(\n",
    "        inputs = prev_layer,\n",
    "        pool_size = 2,\n",
    "        strides = 2\n",
    "    )\n",
    "\n",
    "    prev_layer = tf.contrib.layers.flatten(prev_layer)\n",
    "    flat = prev_layer\n",
    "\n",
    "    prev_layer = noisy_dense(\n",
    "        inputs = prev_layer,\n",
    "        units = 256,\n",
    "        activation = tf.nn.relu,\n",
    "        name = 'dense_1',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "\n",
    "\n",
    "    prev_layer = noisy_dense(\n",
    "        inputs = prev_layer,\n",
    "        units = 256,\n",
    "        activation = tf.nn.relu,\n",
    "        name = 'dense_2',\n",
    "        scope_name = \"conv\"\n",
    "    )\n",
    "\n",
    "    logits = noisy_dense(\n",
    "        inputs = prev_layer,\n",
    "        units = 10,\n",
    "        activation = lambda t:t,\n",
    "        name = 'dense_3',\n",
    "        scope_name = \"conv\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator():\n",
    "    def __init__(self, imgsize, conv_input, logits, cls_no=10):\n",
    "        imgshape = (imgsize, imgsize, 3)\n",
    "        self.x = tf.placeholder(tf.float32, imgshape)\n",
    "        self.y_adv = tf.placeholder(tf.int32, ())\n",
    "        self.x_adv = conv_input\n",
    "\n",
    "        self.assign_op = tf.assign(self.x_adv, self.x)\n",
    "\n",
    "        self.lr = tf.placeholder(tf.float32, ())\n",
    "        labels = tf.one_hot(self.y_adv, cls_no)\n",
    "        self.loss = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=[labels])\n",
    "        self.optim_step = tf.train.GradientDescentOptimizer(self.lr).minimize(self.loss, var_list=[self.x_adv])\n",
    "\n",
    "        self.epsilon = tf.placeholder(tf.float32, ())\n",
    "        below = self.x - self.epsilon\n",
    "        above = self.x + self.epsilon\n",
    "        projected = tf.clip_by_value(tf.clip_by_value(self.x_adv, below, above), 0, 1)\n",
    "        with tf.control_dependencies([projected]):\n",
    "            self.project_step = tf.assign(self.x_adv, projected)\n",
    "\n",
    "    def generate(self, sess, image, target, eps_val=0.01, lr_val=1e-1, num_steps=100):\n",
    "        sess.run(self.assign_op, feed_dict={self.x: image})\n",
    "\n",
    "        for i in range(num_steps):\n",
    "            _, loss_val = sess.run([self.optim_step, self.loss], feed_dict={self.lr: lr_val, self.y_adv: target})\n",
    "            sess.run(self.project_step, feed_dict={self.x: image, self.epsilon: eps_val})\n",
    "            if (i + 1) % 10 == 0:\n",
    "                print('step %d, loss=%g' % (i+1, loss_val))\n",
    "\n",
    "        return sess.run(self.x_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-8-4b7dab3a8ff7>:12: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = tf.nn.softmax(logits)\n",
    "loss=ce(logits, y_)\n",
    "accuracy=acc(pred, y_)\n",
    "\n",
    "theta_conv = tf.trainable_variables(\"conv\")\n",
    "conv_solver = tf.train.AdamOptimizer(learning_rate = 0.001).minimize(loss = loss)\n",
    "\n",
    "fgsm_agent = Generator(32, x, logits)\n",
    "\n",
    "sess=tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(train_itr.initializer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_label = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from new_pretrained/model\n",
      "step 10, loss=0.00479963\n",
      "step 20, loss=0.00260788\n",
      "step 30, loss=0.00165314\n",
      "step 40, loss=0.00117305\n",
      "step 50, loss=0.000913084\n",
      "step 60, loss=0.000742756\n",
      "step 70, loss=0.000628155\n",
      "step 80, loss=0.000546068\n",
      "step 90, loss=0.000482205\n",
      "step 100, loss=0.000432398\n",
      "step 10, loss=0.00348354\n",
      "step 20, loss=0.00185972\n",
      "step 30, loss=0.00128639\n",
      "step 40, loss=0.000988352\n",
      "step 50, loss=0.000806364\n",
      "step 60, loss=0.000681526\n",
      "step 70, loss=0.00059301\n",
      "step 80, loss=0.000527243\n",
      "step 90, loss=0.000475055\n",
      "step 100, loss=0.000432755\n",
      "step 10, loss=0.00238658\n",
      "step 20, loss=0.00114435\n",
      "step 30, loss=0.000758599\n",
      "step 40, loss=0.000577521\n",
      "step 50, loss=0.000472077\n",
      "step 60, loss=0.00039951\n",
      "step 70, loss=0.00034672\n",
      "step 80, loss=0.000306917\n",
      "step 90, loss=0.000276646\n",
      "step 100, loss=0.000252096\n",
      "step 10, loss=0.00757512\n",
      "step 20, loss=0.00319625\n",
      "step 30, loss=0.00215822\n",
      "step 40, loss=0.0016041\n",
      "step 50, loss=0.00127937\n",
      "step 60, loss=0.00106421\n",
      "step 70, loss=0.000918086\n",
      "step 80, loss=0.000809104\n",
      "step 90, loss=0.000724173\n",
      "step 100, loss=0.000655913\n",
      "step 10, loss=0.00305697\n",
      "step 20, loss=0.00197168\n",
      "step 30, loss=0.0014208\n",
      "step 40, loss=0.00112435\n",
      "step 50, loss=0.00094798\n",
      "step 60, loss=0.000819586\n",
      "step 70, loss=0.000721314\n",
      "step 80, loss=0.000644119\n",
      "step 90, loss=0.000582644\n",
      "step 100, loss=0.000532128\n",
      "step 10, loss=0.00985766\n",
      "step 20, loss=0.00470211\n",
      "step 30, loss=0.00304069\n",
      "step 40, loss=0.0022774\n",
      "step 50, loss=0.00182034\n",
      "step 60, loss=0.00151746\n",
      "step 70, loss=0.00130497\n",
      "step 80, loss=0.00115102\n",
      "step 90, loss=0.00103384\n",
      "step 100, loss=0.000940834\n",
      "step 10, loss=0.00788599\n",
      "step 20, loss=0.00409063\n",
      "step 30, loss=0.00277004\n",
      "step 40, loss=0.00202034\n",
      "step 50, loss=0.00160089\n",
      "step 60, loss=0.00131425\n",
      "step 70, loss=0.00111125\n",
      "step 80, loss=0.000964296\n",
      "step 90, loss=0.000851507\n",
      "step 100, loss=0.000763125\n",
      "step 10, loss=0.0011228\n",
      "step 20, loss=0.000890931\n",
      "step 30, loss=0.000728699\n",
      "step 40, loss=0.000616956\n",
      "step 50, loss=0.000534987\n",
      "step 60, loss=0.000472791\n",
      "step 70, loss=0.000424057\n",
      "step 80, loss=0.000385091\n",
      "step 90, loss=0.000353155\n",
      "step 100, loss=0.000326223\n",
      "step 10, loss=9.08334e-05\n",
      "step 20, loss=8.68998e-05\n",
      "step 30, loss=8.33238e-05\n",
      "step 40, loss=7.93902e-05\n",
      "step 50, loss=7.59334e-05\n",
      "step 60, loss=7.25958e-05\n",
      "step 70, loss=6.96158e-05\n",
      "step 80, loss=6.6755e-05\n",
      "step 90, loss=6.42517e-05\n",
      "step 100, loss=6.19869e-05\n",
      "step 10, loss=0.000858058\n",
      "step 20, loss=0.000710235\n",
      "step 30, loss=0.000609927\n",
      "step 40, loss=0.000536298\n",
      "step 50, loss=0.000479941\n",
      "step 60, loss=0.000435734\n",
      "step 70, loss=0.000399152\n",
      "step 80, loss=0.000368646\n",
      "step 90, loss=0.000343025\n",
      "step 100, loss=0.000320502\n",
      "step 10, loss=0.0700329\n",
      "step 20, loss=0.0168725\n",
      "step 30, loss=0.00815325\n",
      "step 40, loss=0.00543818\n",
      "step 50, loss=0.00415403\n",
      "step 60, loss=0.00341963\n",
      "step 70, loss=0.00292766\n",
      "step 80, loss=0.00255615\n",
      "step 90, loss=0.00226943\n",
      "step 100, loss=0.00202439\n",
      "step 10, loss=0.00451474\n",
      "step 20, loss=0.0027037\n",
      "step 30, loss=0.00189649\n",
      "step 40, loss=0.00143425\n",
      "step 50, loss=0.00115828\n",
      "step 60, loss=0.00097287\n",
      "step 70, loss=0.000842455\n",
      "step 80, loss=0.000741088\n",
      "step 90, loss=0.00066175\n",
      "step 100, loss=0.000601111\n",
      "step 10, loss=0.00289438\n",
      "step 20, loss=0.00158018\n",
      "step 30, loss=0.00113709\n",
      "step 40, loss=0.00090558\n",
      "step 50, loss=0.000760028\n",
      "step 60, loss=0.000648169\n",
      "step 70, loss=0.000550953\n",
      "step 80, loss=0.00048006\n",
      "step 90, loss=0.00042644\n",
      "step 100, loss=0.000386998\n",
      "step 10, loss=0.000690937\n",
      "step 20, loss=0.000577641\n",
      "step 30, loss=0.000497337\n",
      "step 40, loss=0.000437641\n",
      "step 50, loss=0.000391049\n",
      "step 60, loss=0.000353631\n",
      "step 70, loss=0.000322528\n",
      "step 80, loss=0.000296906\n",
      "step 90, loss=0.000275216\n",
      "step 100, loss=0.000256506\n",
      "step 10, loss=0.00191374\n",
      "step 20, loss=0.00109851\n",
      "step 30, loss=0.00073811\n",
      "step 40, loss=0.000560603\n",
      "step 50, loss=0.000447292\n",
      "step 60, loss=0.00037234\n",
      "step 70, loss=0.000319668\n",
      "step 80, loss=0.000279864\n",
      "step 90, loss=0.00024864\n",
      "step 100, loss=0.000223612\n",
      "step 10, loss=0.00327432\n",
      "step 20, loss=0.00178012\n",
      "step 30, loss=0.00128247\n",
      "step 40, loss=0.00102015\n",
      "step 50, loss=0.000848648\n",
      "step 60, loss=0.000713451\n",
      "step 70, loss=0.000619935\n",
      "step 80, loss=0.000546306\n",
      "step 90, loss=0.000489592\n",
      "step 100, loss=0.000444552\n",
      "step 10, loss=0.00425327\n",
      "step 20, loss=0.00227015\n",
      "step 30, loss=0.00150305\n",
      "step 40, loss=0.00109386\n",
      "step 50, loss=0.000866514\n",
      "step 60, loss=0.000723934\n",
      "step 70, loss=0.000619696\n",
      "step 80, loss=0.000540945\n",
      "step 90, loss=0.000480656\n",
      "step 100, loss=0.00043347\n",
      "step 10, loss=0.0027591\n",
      "step 20, loss=0.00181391\n",
      "step 30, loss=0.00134509\n",
      "step 40, loss=0.0010766\n",
      "step 50, loss=0.000891884\n",
      "step 60, loss=0.000771106\n",
      "step 70, loss=0.000682955\n",
      "step 80, loss=0.000606234\n",
      "step 90, loss=0.000548451\n",
      "step 100, loss=0.000501149\n",
      "step 10, loss=0.00579345\n",
      "step 20, loss=0.00325353\n",
      "step 30, loss=0.00233758\n",
      "step 40, loss=0.00183961\n",
      "step 50, loss=0.00150853\n",
      "step 60, loss=0.00127294\n",
      "step 70, loss=0.00110041\n",
      "step 80, loss=0.000970727\n",
      "step 90, loss=0.000868777\n",
      "step 100, loss=0.000789569\n",
      "step 10, loss=0.000827328\n",
      "step 20, loss=0.000650314\n",
      "step 30, loss=0.000546544\n",
      "step 40, loss=0.000474698\n",
      "step 50, loss=0.000422269\n",
      "step 60, loss=0.000383304\n",
      "step 70, loss=0.00035244\n",
      "step 80, loss=0.000327295\n",
      "step 90, loss=0.000305368\n",
      "step 100, loss=0.000286419\n",
      "step 10, loss=0.00184378\n",
      "step 20, loss=0.00101336\n",
      "step 30, loss=0.000709282\n",
      "step 40, loss=0.000547617\n",
      "step 50, loss=0.000446935\n",
      "step 60, loss=0.000377226\n",
      "step 70, loss=0.000326461\n",
      "step 80, loss=0.000288445\n",
      "step 90, loss=0.000258532\n",
      "step 100, loss=0.000233504\n",
      "step 10, loss=0.000887358\n",
      "step 20, loss=0.000678428\n",
      "step 30, loss=0.000556791\n",
      "step 40, loss=0.000472791\n",
      "step 50, loss=0.000411545\n",
      "step 60, loss=0.00036388\n",
      "step 70, loss=0.000326103\n",
      "step 80, loss=0.000295715\n",
      "step 90, loss=0.000270688\n",
      "step 100, loss=0.000250189\n",
      "step 10, loss=0.00372561\n",
      "step 20, loss=0.00200059\n",
      "step 30, loss=0.00140068\n",
      "step 40, loss=0.00107802\n",
      "step 50, loss=0.000867229\n",
      "step 60, loss=0.000728104\n",
      "step 70, loss=0.000624104\n",
      "step 80, loss=0.000545949\n",
      "step 90, loss=0.000486017\n",
      "step 100, loss=0.00043919\n",
      "step 10, loss=0.00312959\n",
      "step 20, loss=0.00154305\n",
      "step 30, loss=0.00109553\n",
      "step 40, loss=0.000859249\n",
      "step 50, loss=0.000706304\n",
      "step 60, loss=0.000596226\n",
      "step 70, loss=0.000517592\n",
      "step 80, loss=0.000458374\n",
      "step 90, loss=0.000411426\n",
      "step 100, loss=0.000373413\n",
      "step 10, loss=0.000448841\n",
      "step 20, loss=0.000391049\n",
      "step 30, loss=0.000347316\n",
      "step 40, loss=0.000312518\n",
      "step 50, loss=0.000284155\n",
      "step 60, loss=0.000260558\n",
      "step 70, loss=0.000240774\n",
      "step 80, loss=0.000223731\n",
      "step 90, loss=0.000209071\n",
      "step 100, loss=0.000196676\n",
      "step 10, loss=0.00140592\n",
      "step 20, loss=0.000764674\n",
      "step 30, loss=0.000529864\n",
      "step 40, loss=0.000404038\n",
      "step 50, loss=0.000328487\n",
      "step 60, loss=0.000281294\n",
      "step 70, loss=0.000246733\n",
      "step 80, loss=0.000219917\n",
      "step 90, loss=0.000198106\n",
      "step 100, loss=0.000180109\n",
      "step 10, loss=0.00504151\n",
      "step 20, loss=0.00337412\n",
      "step 30, loss=0.00248838\n",
      "step 40, loss=0.00196728\n",
      "step 50, loss=0.00164826\n",
      "step 60, loss=0.00142663\n",
      "step 70, loss=0.00127056\n",
      "step 80, loss=0.00115042\n",
      "step 90, loss=0.00105171\n",
      "step 100, loss=0.00096763\n",
      "step 10, loss=0.00338327\n",
      "step 20, loss=0.0016792\n",
      "step 30, loss=0.00113113\n",
      "step 40, loss=0.000872946\n",
      "step 50, loss=0.000720122\n",
      "step 60, loss=0.000620649\n",
      "step 70, loss=0.000551072\n",
      "step 80, loss=0.000497813\n",
      "step 90, loss=0.000455157\n",
      "step 100, loss=0.000420005\n",
      "step 10, loss=0.000328606\n",
      "step 20, loss=0.000293212\n",
      "step 30, loss=0.000265444\n",
      "step 40, loss=0.000243634\n",
      "step 50, loss=0.000223969\n",
      "step 60, loss=0.000205496\n",
      "step 70, loss=0.000189882\n",
      "step 80, loss=0.000176414\n",
      "step 90, loss=0.000165091\n",
      "step 100, loss=0.000155198\n",
      "step 10, loss=0.000196676\n",
      "step 20, loss=0.000183685\n",
      "step 30, loss=0.000172123\n",
      "step 40, loss=0.000162231\n",
      "step 50, loss=0.000153411\n",
      "step 60, loss=0.000145782\n",
      "step 70, loss=0.000138273\n",
      "step 80, loss=0.000131598\n",
      "step 90, loss=0.0001254\n",
      "step 100, loss=0.000119321\n",
      "step 10, loss=0.00257042\n",
      "step 20, loss=0.00160506\n",
      "step 30, loss=0.00122996\n",
      "step 40, loss=0.000985852\n",
      "step 50, loss=0.000791832\n",
      "step 60, loss=0.000672829\n",
      "step 70, loss=0.00059015\n",
      "step 80, loss=0.000528434\n",
      "step 90, loss=0.00048149\n",
      "step 100, loss=0.000444671\n",
      "step 10, loss=0.00394911\n",
      "step 20, loss=0.00249646\n",
      "step 30, loss=0.00182224\n",
      "step 40, loss=0.00143032\n",
      "step 50, loss=0.00114245\n",
      "step 60, loss=0.000957031\n",
      "step 70, loss=0.000827566\n",
      "step 80, loss=0.000728818\n",
      "step 90, loss=0.000651386\n",
      "step 100, loss=0.000589435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 10, loss=0.00585579\n",
      "step 20, loss=0.00315169\n",
      "step 30, loss=0.00223851\n",
      "step 40, loss=0.00174239\n",
      "step 50, loss=0.00142866\n",
      "step 60, loss=0.00121115\n",
      "step 70, loss=0.00105671\n",
      "step 80, loss=0.000935951\n",
      "step 90, loss=0.000836261\n",
      "step 100, loss=0.000756812\n",
      "step 10, loss=0.0015603\n",
      "step 20, loss=0.00114578\n",
      "step 30, loss=0.000915108\n",
      "step 40, loss=0.0007611\n",
      "step 50, loss=0.000654721\n",
      "step 60, loss=0.00057633\n",
      "step 70, loss=0.000515209\n",
      "step 80, loss=0.000466476\n",
      "step 90, loss=0.000426321\n",
      "step 100, loss=0.000393313\n",
      "step 10, loss=0.00360328\n",
      "step 20, loss=0.00244259\n",
      "step 30, loss=0.00181177\n",
      "step 40, loss=0.00142342\n",
      "step 50, loss=0.00118221\n",
      "step 60, loss=0.00101062\n",
      "step 70, loss=0.000870802\n",
      "step 80, loss=0.000753357\n",
      "step 90, loss=0.00066592\n",
      "step 100, loss=0.000598847\n",
      "step 10, loss=0.00880478\n",
      "step 20, loss=0.00473592\n",
      "step 30, loss=0.00312091\n",
      "step 40, loss=0.00221091\n",
      "step 50, loss=0.00170241\n",
      "step 60, loss=0.00138997\n",
      "step 70, loss=0.0011553\n",
      "step 80, loss=0.000999666\n",
      "step 90, loss=0.000883189\n",
      "step 100, loss=0.000779087\n",
      "step 10, loss=0.0080039\n",
      "step 20, loss=0.00387216\n",
      "step 30, loss=0.00251026\n",
      "step 40, loss=0.001822\n",
      "step 50, loss=0.00144996\n",
      "step 60, loss=0.0012227\n",
      "step 70, loss=0.00106028\n",
      "step 80, loss=0.000940238\n",
      "step 90, loss=0.000845552\n",
      "step 100, loss=0.000770034\n",
      "step 10, loss=0.00462913\n",
      "step 20, loss=0.00229715\n",
      "step 30, loss=0.00151067\n",
      "step 40, loss=0.00113244\n",
      "step 50, loss=0.000906771\n",
      "step 60, loss=0.000758718\n",
      "step 70, loss=0.000654721\n",
      "step 80, loss=0.000578594\n",
      "step 90, loss=0.000518783\n",
      "step 100, loss=0.000470289\n",
      "step 10, loss=0.001718\n",
      "step 20, loss=0.00119067\n",
      "step 30, loss=0.000914989\n",
      "step 40, loss=0.000742398\n",
      "step 50, loss=0.000628631\n",
      "step 60, loss=0.000549761\n",
      "step 70, loss=0.000488877\n",
      "step 80, loss=0.00044062\n",
      "step 90, loss=0.000405468\n",
      "step 100, loss=0.000376035\n",
      "step 10, loss=0.00391598\n",
      "step 20, loss=0.00215536\n",
      "step 30, loss=0.00152769\n",
      "step 40, loss=0.0011821\n",
      "step 50, loss=0.000970846\n",
      "step 60, loss=0.000827685\n",
      "step 70, loss=0.000722862\n",
      "step 80, loss=0.000642332\n",
      "step 90, loss=0.000577045\n",
      "step 100, loss=0.000523907\n",
      "step 10, loss=0.00585721\n",
      "step 20, loss=0.00301336\n",
      "step 30, loss=0.00204533\n",
      "step 40, loss=0.00156959\n",
      "step 50, loss=0.00126377\n",
      "step 60, loss=0.00104432\n",
      "step 70, loss=0.000887239\n",
      "step 80, loss=0.000764674\n",
      "step 90, loss=0.000672829\n",
      "step 100, loss=0.000602779\n",
      "step 10, loss=0.00770584\n",
      "step 20, loss=0.00309798\n",
      "step 30, loss=0.00192861\n",
      "step 40, loss=0.0013358\n",
      "step 50, loss=0.00103587\n",
      "step 60, loss=0.000850673\n",
      "step 70, loss=0.00072989\n",
      "step 80, loss=0.000633754\n",
      "step 90, loss=0.000550834\n",
      "step 100, loss=0.000486971\n",
      "step 10, loss=0.0045946\n",
      "step 20, loss=0.00219034\n",
      "step 30, loss=0.00141854\n",
      "step 40, loss=0.0010729\n",
      "step 50, loss=0.000871517\n",
      "step 60, loss=0.000735608\n",
      "step 70, loss=0.000637209\n",
      "step 80, loss=0.000563105\n",
      "step 90, loss=0.000507703\n",
      "step 100, loss=0.000462663\n",
      "step 10, loss=0.00468882\n",
      "step 20, loss=0.00228715\n",
      "step 30, loss=0.00151198\n",
      "step 40, loss=0.00114971\n",
      "step 50, loss=0.000935832\n",
      "step 60, loss=0.000789212\n",
      "step 70, loss=0.00068641\n",
      "step 80, loss=0.000609093\n",
      "step 90, loss=0.000543208\n",
      "step 100, loss=0.000489354\n",
      "step 10, loss=0.00218177\n",
      "step 20, loss=0.00114078\n",
      "step 30, loss=0.000757884\n",
      "step 40, loss=0.000570492\n",
      "step 50, loss=0.000459565\n",
      "step 60, loss=0.000384376\n",
      "step 70, loss=0.000331704\n",
      "step 80, loss=0.000292854\n",
      "step 90, loss=0.000262703\n",
      "step 100, loss=0.000238748\n",
      "step 10, loss=0.0361762\n",
      "step 20, loss=0.0156097\n",
      "step 30, loss=0.00820397\n",
      "step 40, loss=0.00475823\n",
      "step 50, loss=0.00336961\n",
      "step 60, loss=0.0025181\n",
      "step 70, loss=0.00203272\n",
      "step 80, loss=0.00167385\n",
      "step 90, loss=0.00144139\n",
      "step 100, loss=0.00127318\n",
      "step 10, loss=3.09944e-06\n",
      "step 20, loss=3.09944e-06\n",
      "step 30, loss=3.09944e-06\n",
      "step 40, loss=3.09944e-06\n",
      "step 50, loss=3.09944e-06\n",
      "step 60, loss=3.09944e-06\n",
      "step 70, loss=3.09944e-06\n",
      "step 80, loss=3.09944e-06\n",
      "step 90, loss=3.09944e-06\n",
      "step 100, loss=3.09944e-06\n",
      "step 10, loss=0.00276006\n",
      "step 20, loss=0.00154602\n",
      "step 30, loss=0.00108386\n",
      "step 40, loss=0.000843527\n",
      "step 50, loss=0.000692604\n",
      "step 60, loss=0.000589912\n",
      "step 70, loss=0.000515447\n",
      "step 80, loss=0.00045885\n",
      "step 90, loss=0.000417145\n",
      "step 100, loss=0.000383304\n",
      "step 10, loss=0.00644711\n",
      "step 20, loss=0.00334561\n",
      "step 30, loss=0.00204426\n",
      "step 40, loss=0.00145044\n",
      "step 50, loss=0.00113006\n",
      "step 60, loss=0.000945598\n",
      "step 70, loss=0.000801242\n",
      "step 80, loss=0.000694511\n",
      "step 90, loss=0.000616122\n",
      "step 100, loss=0.000554765\n",
      "step 10, loss=0.00217892\n",
      "step 20, loss=0.00143913\n",
      "step 30, loss=0.00103861\n",
      "step 40, loss=0.000799694\n",
      "step 50, loss=0.000643285\n",
      "step 60, loss=0.000537847\n",
      "step 70, loss=0.000460638\n",
      "step 80, loss=0.000399867\n",
      "step 90, loss=0.000354227\n",
      "step 100, loss=0.000319787\n",
      "step 10, loss=0.00074752\n",
      "step 20, loss=0.000491022\n",
      "step 30, loss=0.000377941\n",
      "step 40, loss=0.000311088\n",
      "step 50, loss=0.000265325\n",
      "step 60, loss=0.000231239\n",
      "step 70, loss=0.000204304\n",
      "step 80, loss=0.00018297\n",
      "step 90, loss=0.000165806\n",
      "step 100, loss=0.000151861\n",
      "step 10, loss=0.00338042\n",
      "step 20, loss=0.00174799\n",
      "step 30, loss=0.00123437\n",
      "step 40, loss=0.000974657\n",
      "step 50, loss=0.000808746\n",
      "step 60, loss=0.000694034\n",
      "step 70, loss=0.000605876\n",
      "step 80, loss=0.000533796\n",
      "step 90, loss=0.000476485\n",
      "step 100, loss=0.000430849\n",
      "step 10, loss=0.00474612\n",
      "step 20, loss=0.00227312\n",
      "step 30, loss=0.00156316\n",
      "step 40, loss=0.0012015\n",
      "step 50, loss=0.000988114\n",
      "step 60, loss=0.000839715\n",
      "step 70, loss=0.000729533\n",
      "step 80, loss=0.000644238\n",
      "step 90, loss=0.000576926\n",
      "step 100, loss=0.000523192\n",
      "step 10, loss=0.00330616\n",
      "step 20, loss=0.001765\n",
      "step 30, loss=0.00123353\n",
      "step 40, loss=0.000948456\n",
      "step 50, loss=0.000775871\n",
      "step 60, loss=0.000661631\n",
      "step 70, loss=0.000580381\n",
      "step 80, loss=0.000518307\n",
      "step 90, loss=0.000464927\n",
      "step 100, loss=0.000420959\n",
      "step 10, loss=0.00281177\n",
      "step 20, loss=0.00148698\n",
      "step 30, loss=0.00103003\n",
      "step 40, loss=0.000798145\n",
      "step 50, loss=0.000647216\n",
      "step 60, loss=0.000543447\n",
      "step 70, loss=0.000470289\n",
      "step 80, loss=0.000413809\n",
      "step 90, loss=0.000369838\n",
      "step 100, loss=0.000334207\n",
      "step 10, loss=0.00810382\n",
      "step 20, loss=0.00400372\n",
      "step 30, loss=0.00279096\n",
      "step 40, loss=0.00213455\n",
      "step 50, loss=0.00167777\n",
      "step 60, loss=0.00134366\n",
      "step 70, loss=0.00111434\n",
      "step 80, loss=0.000949409\n",
      "step 90, loss=0.000829353\n",
      "step 100, loss=0.000740611\n",
      "step 10, loss=0.00441659\n",
      "step 20, loss=0.00229786\n",
      "step 30, loss=0.00149722\n",
      "step 40, loss=0.00109315\n",
      "step 50, loss=0.000864847\n",
      "step 60, loss=0.000719646\n",
      "step 70, loss=0.000616956\n",
      "step 80, loss=0.000540945\n",
      "step 90, loss=0.000482919\n",
      "step 100, loss=0.000437164\n",
      "step 10, loss=0.00142901\n",
      "step 20, loss=0.000923922\n",
      "step 30, loss=0.000694987\n",
      "step 40, loss=0.000548808\n",
      "step 50, loss=0.000453369\n",
      "step 60, loss=0.000380682\n",
      "step 70, loss=0.000329202\n",
      "step 80, loss=0.000291663\n",
      "step 90, loss=0.00026163\n",
      "step 100, loss=0.000238271\n",
      "step 10, loss=0.00458831\n",
      "step 20, loss=0.00271512\n",
      "step 30, loss=0.00186793\n",
      "step 40, loss=0.00141092\n",
      "step 50, loss=0.00113637\n",
      "step 60, loss=0.000954054\n",
      "step 70, loss=0.000825779\n",
      "step 80, loss=0.00073132\n",
      "step 90, loss=0.000658891\n",
      "step 100, loss=0.000600396\n",
      "step 10, loss=0.00136175\n",
      "step 20, loss=0.0008284\n",
      "step 30, loss=0.000600515\n",
      "step 40, loss=0.000473149\n",
      "step 50, loss=0.000391288\n",
      "step 60, loss=0.000335756\n",
      "step 70, loss=0.000296191\n",
      "step 80, loss=0.000261153\n",
      "step 90, loss=0.000232312\n",
      "step 100, loss=0.000209071\n",
      "step 10, loss=0.00320695\n",
      "step 20, loss=0.00148544\n",
      "step 30, loss=0.000988472\n",
      "step 40, loss=0.00075026\n",
      "step 50, loss=0.000608974\n",
      "step 60, loss=0.000513779\n",
      "step 70, loss=0.000449795\n",
      "step 80, loss=0.000399391\n",
      "step 90, loss=0.00035959\n",
      "step 100, loss=0.000327653\n",
      "step 10, loss=0.00174216\n",
      "step 20, loss=0.000987281\n",
      "step 30, loss=0.000708329\n",
      "step 40, loss=0.000560484\n",
      "step 50, loss=0.000471004\n",
      "step 60, loss=0.000408208\n",
      "step 70, loss=0.000362331\n",
      "step 80, loss=0.000326342\n",
      "step 90, loss=0.00029774\n",
      "step 100, loss=0.000274859\n",
      "step 10, loss=0.00347392\n",
      "step 20, loss=0.00165469\n",
      "step 30, loss=0.00110827\n",
      "step 40, loss=0.000847934\n",
      "step 50, loss=0.000675688\n",
      "step 60, loss=0.000561914\n",
      "step 70, loss=0.00048423\n",
      "step 80, loss=0.000427155\n",
      "step 90, loss=0.000383423\n",
      "step 100, loss=0.000349341\n",
      "step 10, loss=0.00603449\n",
      "step 20, loss=0.00286324\n",
      "step 30, loss=0.00182998\n",
      "step 40, loss=0.00133509\n",
      "step 50, loss=0.00105397\n",
      "step 60, loss=0.000873303\n",
      "step 70, loss=0.000747878\n",
      "step 80, loss=0.000655555\n",
      "step 90, loss=0.000585742\n",
      "step 100, loss=0.000530698\n",
      "step 10, loss=0.00440069\n",
      "step 20, loss=0.00248921\n",
      "step 30, loss=0.00171978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 40, loss=0.0013208\n",
      "step 50, loss=0.0010473\n",
      "step 60, loss=0.000872112\n",
      "step 70, loss=0.000751213\n",
      "step 80, loss=0.000663061\n",
      "step 90, loss=0.00059301\n",
      "step 100, loss=0.000537132\n",
      "step 10, loss=0.00220437\n",
      "step 20, loss=0.00116293\n",
      "step 30, loss=0.000776704\n",
      "step 40, loss=0.00058741\n",
      "step 50, loss=0.000470289\n",
      "step 60, loss=0.000389619\n",
      "step 70, loss=0.000332658\n",
      "step 80, loss=0.000290709\n",
      "step 90, loss=0.000259008\n",
      "step 100, loss=0.000234457\n",
      "step 10, loss=0.00924792\n",
      "step 20, loss=0.00451308\n",
      "step 30, loss=0.0030136\n",
      "step 40, loss=0.00228382\n",
      "step 50, loss=0.00181022\n",
      "step 60, loss=0.00147079\n",
      "step 70, loss=0.00124508\n",
      "step 80, loss=0.00108374\n",
      "step 90, loss=0.000958817\n",
      "step 100, loss=0.000855199\n",
      "step 10, loss=0.00344933\n",
      "step 20, loss=0.00179582\n",
      "step 30, loss=0.0012527\n",
      "step 40, loss=0.000978944\n",
      "step 50, loss=0.000821253\n",
      "step 60, loss=0.000709163\n",
      "step 70, loss=0.000628989\n",
      "step 80, loss=0.000565131\n",
      "step 90, loss=0.000512945\n",
      "step 100, loss=0.000471481\n",
      "step 10, loss=0.00388439\n",
      "step 20, loss=0.00218213\n",
      "step 30, loss=0.00151305\n",
      "step 40, loss=0.00116733\n",
      "step 50, loss=0.000955125\n",
      "step 60, loss=0.000811962\n",
      "step 70, loss=0.000709759\n",
      "step 80, loss=0.000631729\n",
      "step 90, loss=0.000570254\n",
      "step 100, loss=0.000520452\n",
      "step 10, loss=0.00182771\n",
      "step 20, loss=0.00134771\n",
      "step 30, loss=0.00108076\n",
      "step 40, loss=0.00090296\n",
      "step 50, loss=0.00077456\n",
      "step 60, loss=0.000682598\n",
      "step 70, loss=0.000609093\n",
      "step 80, loss=0.000548212\n",
      "step 90, loss=0.000499124\n",
      "step 100, loss=0.00045754\n",
      "step 10, loss=0.00715574\n",
      "step 20, loss=0.00345574\n",
      "step 30, loss=0.0021757\n",
      "step 40, loss=0.00160982\n",
      "step 50, loss=0.00129818\n",
      "step 60, loss=0.00109327\n",
      "step 70, loss=0.000938333\n",
      "step 80, loss=0.000821968\n",
      "step 90, loss=0.000732273\n",
      "step 100, loss=0.000661274\n",
      "step 10, loss=0.00710887\n",
      "step 20, loss=0.00313802\n",
      "step 30, loss=0.00187757\n",
      "step 40, loss=0.00132021\n",
      "step 50, loss=0.00102432\n",
      "step 60, loss=0.000837452\n",
      "step 70, loss=0.000706542\n",
      "step 80, loss=0.000611595\n",
      "step 90, loss=0.000540587\n",
      "step 100, loss=0.000486494\n",
      "step 10, loss=0.000684146\n",
      "step 20, loss=0.000516758\n",
      "step 30, loss=0.000414405\n",
      "step 40, loss=0.000345886\n",
      "step 50, loss=0.000297383\n",
      "step 60, loss=0.000260677\n",
      "step 70, loss=0.000231597\n",
      "step 80, loss=0.000208475\n",
      "step 90, loss=0.000190121\n",
      "step 100, loss=0.000175341\n",
      "step 10, loss=0.0054479\n",
      "step 20, loss=0.00283732\n",
      "step 30, loss=0.0019655\n",
      "step 40, loss=0.00147068\n",
      "step 50, loss=0.00116733\n",
      "step 60, loss=0.000959294\n",
      "step 70, loss=0.000808032\n",
      "step 80, loss=0.000700467\n",
      "step 90, loss=0.000620173\n",
      "step 100, loss=0.000556672\n",
      "step 10, loss=0.00761203\n",
      "step 20, loss=0.0039497\n",
      "step 30, loss=0.00280951\n",
      "step 40, loss=0.00222471\n",
      "step 50, loss=0.00185841\n",
      "step 60, loss=0.00158935\n",
      "step 70, loss=0.00138021\n",
      "step 80, loss=0.0012227\n",
      "step 90, loss=0.00109946\n",
      "step 100, loss=0.00100086\n",
      "step 10, loss=0.00344172\n",
      "step 20, loss=0.00196895\n",
      "step 30, loss=0.00141413\n",
      "step 40, loss=0.00111732\n",
      "step 50, loss=0.000927257\n",
      "step 60, loss=0.000799813\n",
      "step 70, loss=0.000701301\n",
      "step 80, loss=0.000623389\n",
      "step 90, loss=0.000563224\n",
      "step 100, loss=0.000512826\n",
      "step 10, loss=0.00863012\n",
      "step 20, loss=0.00452708\n",
      "step 30, loss=0.00317581\n",
      "step 40, loss=0.00248184\n",
      "step 50, loss=0.00203759\n",
      "step 60, loss=0.00173466\n",
      "step 70, loss=0.00151079\n",
      "step 80, loss=0.00133663\n",
      "step 90, loss=0.00119686\n",
      "step 100, loss=0.00108148\n",
      "step 10, loss=0.00301799\n",
      "step 20, loss=0.00203462\n",
      "step 30, loss=0.00156173\n",
      "step 40, loss=0.00127532\n",
      "step 50, loss=0.00108207\n",
      "step 60, loss=0.000936665\n",
      "step 70, loss=0.000831378\n",
      "step 80, loss=0.000749069\n",
      "step 90, loss=0.000682836\n",
      "step 100, loss=0.00062601\n",
      "step 10, loss=0.000521047\n",
      "step 20, loss=0.000454323\n",
      "step 30, loss=0.000404753\n",
      "step 40, loss=0.000365191\n",
      "step 50, loss=0.000332777\n",
      "step 60, loss=0.000305368\n",
      "step 70, loss=0.000282367\n",
      "step 80, loss=0.000263656\n",
      "step 90, loss=0.000248163\n",
      "step 100, loss=0.000234338\n",
      "step 10, loss=0.000798503\n",
      "step 20, loss=0.000665324\n",
      "step 30, loss=0.000576568\n",
      "step 40, loss=0.000510562\n",
      "step 50, loss=0.000457897\n",
      "step 60, loss=0.00041512\n",
      "step 70, loss=0.000379967\n",
      "step 80, loss=0.000350295\n",
      "step 90, loss=0.000325031\n",
      "step 100, loss=0.000303222\n",
      "step 10, loss=0.00373096\n",
      "step 20, loss=0.00181213\n",
      "step 30, loss=0.00121246\n",
      "step 40, loss=0.000911059\n",
      "step 50, loss=0.000741207\n",
      "step 60, loss=0.000626249\n",
      "step 70, loss=0.000543804\n",
      "step 80, loss=0.000482085\n",
      "step 90, loss=0.000433709\n",
      "step 100, loss=0.000394505\n",
      "step 10, loss=0.00478326\n",
      "step 20, loss=0.00297996\n",
      "step 30, loss=0.00218558\n",
      "step 40, loss=0.00171014\n",
      "step 50, loss=0.00139735\n",
      "step 60, loss=0.00119245\n",
      "step 70, loss=0.00104016\n",
      "step 80, loss=0.000917014\n",
      "step 90, loss=0.000821015\n",
      "step 100, loss=0.000741803\n",
      "step 10, loss=0.000663537\n",
      "step 20, loss=0.000584074\n",
      "step 30, loss=0.000517473\n",
      "step 40, loss=0.000464093\n",
      "step 50, loss=0.000420601\n",
      "step 60, loss=0.000382946\n",
      "step 70, loss=0.000355419\n",
      "step 80, loss=0.000331466\n",
      "step 90, loss=0.000310492\n",
      "step 100, loss=0.000292139\n",
      "step 10, loss=0.00437909\n",
      "step 20, loss=0.00228763\n",
      "step 30, loss=0.0016072\n",
      "step 40, loss=0.00126901\n",
      "step 50, loss=0.00105683\n",
      "step 60, loss=0.00091356\n",
      "step 70, loss=0.000807555\n",
      "step 80, loss=0.000725245\n",
      "step 90, loss=0.00065901\n",
      "step 100, loss=0.0006054\n",
      "step 10, loss=0.000901412\n",
      "step 20, loss=0.000654721\n",
      "step 30, loss=0.000516043\n",
      "step 40, loss=0.000427274\n",
      "step 50, loss=0.000365786\n",
      "step 60, loss=0.000320383\n",
      "step 70, loss=0.00028475\n",
      "step 80, loss=0.000256744\n",
      "step 90, loss=0.000233742\n",
      "step 100, loss=0.000214673\n",
      "step 10, loss=0.0137595\n",
      "step 20, loss=0.00622785\n",
      "step 30, loss=0.00375554\n",
      "step 40, loss=0.00270037\n",
      "step 50, loss=0.00211896\n",
      "step 60, loss=0.00174751\n",
      "step 70, loss=0.00144044\n",
      "step 80, loss=0.00121496\n",
      "step 90, loss=0.00105087\n",
      "step 100, loss=0.000926066\n",
      "step 10, loss=0.00587676\n",
      "step 20, loss=0.00247541\n",
      "step 30, loss=0.00148913\n",
      "step 40, loss=0.00108362\n",
      "step 50, loss=0.000858534\n",
      "step 60, loss=0.000707614\n",
      "step 70, loss=0.000598728\n",
      "step 80, loss=0.000520809\n",
      "step 90, loss=0.000459804\n",
      "step 100, loss=0.000412022\n",
      "step 10, loss=0.00104694\n",
      "step 20, loss=0.000875209\n",
      "step 30, loss=0.000755263\n",
      "step 40, loss=0.000662584\n",
      "step 50, loss=0.000589674\n",
      "step 60, loss=0.000530936\n",
      "step 70, loss=0.000480298\n",
      "step 80, loss=0.000438356\n",
      "step 90, loss=0.000403085\n",
      "step 100, loss=0.000373532\n",
      "step 10, loss=0.00886717\n",
      "step 20, loss=0.00474826\n",
      "step 30, loss=0.00331662\n",
      "step 40, loss=0.00258731\n",
      "step 50, loss=0.0020113\n",
      "step 60, loss=0.00155733\n",
      "step 70, loss=0.00126246\n",
      "step 80, loss=0.00107445\n",
      "step 90, loss=0.000915823\n",
      "step 100, loss=0.000798145\n",
      "step 10, loss=0.00138378\n",
      "step 20, loss=0.000993354\n",
      "step 30, loss=0.000794453\n",
      "step 40, loss=0.00065079\n",
      "step 50, loss=0.00054583\n",
      "step 60, loss=0.000473149\n",
      "step 70, loss=0.00042358\n",
      "step 80, loss=0.000384376\n",
      "step 90, loss=0.000352678\n",
      "step 100, loss=0.000324673\n",
      "step 10, loss=7.37878e-05\n",
      "step 20, loss=7.14038e-05\n",
      "step 30, loss=6.90198e-05\n",
      "step 40, loss=6.69934e-05\n",
      "step 50, loss=6.4967e-05\n",
      "step 60, loss=6.32981e-05\n",
      "step 70, loss=6.15101e-05\n",
      "step 80, loss=5.99605e-05\n",
      "step 90, loss=5.84108e-05\n",
      "step 100, loss=5.70996e-05\n",
      "step 10, loss=0.00162719\n",
      "step 20, loss=0.00108041\n",
      "step 30, loss=0.000803267\n",
      "step 40, loss=0.000632563\n",
      "step 50, loss=0.000522\n",
      "step 60, loss=0.000448841\n",
      "step 70, loss=0.000395101\n",
      "step 80, loss=0.00035244\n",
      "step 90, loss=0.000317881\n",
      "step 100, loss=0.000290113\n",
      "step 10, loss=0.0106164\n",
      "step 20, loss=0.0061403\n",
      "step 30, loss=0.00427582\n",
      "step 40, loss=0.00319756\n",
      "step 50, loss=0.00249278\n",
      "step 60, loss=0.00199024\n",
      "step 70, loss=0.00166647\n",
      "step 80, loss=0.00144556\n",
      "step 90, loss=0.00128056\n",
      "step 100, loss=0.00114887\n",
      "step 10, loss=0.004086\n",
      "step 20, loss=0.00261132\n",
      "step 30, loss=0.00192802\n",
      "step 40, loss=0.00153745\n",
      "step 50, loss=0.00126937\n",
      "step 60, loss=0.00107922\n",
      "step 70, loss=0.000923326\n",
      "step 80, loss=0.00080696\n",
      "step 90, loss=0.000717502\n",
      "step 100, loss=0.000644714\n",
      "step 10, loss=0.00451937\n",
      "step 20, loss=0.00216131\n",
      "step 30, loss=0.00143282\n",
      "step 40, loss=0.00106933\n",
      "step 50, loss=0.000872112\n",
      "step 60, loss=0.000735608\n",
      "step 70, loss=0.000636613\n",
      "step 80, loss=0.000561795\n",
      "step 90, loss=0.000502937\n",
      "step 100, loss=0.000455514\n",
      "step 10, loss=0.00118007\n",
      "step 20, loss=0.000687959\n",
      "step 30, loss=0.000495788\n",
      "step 40, loss=0.000398199\n",
      "step 50, loss=0.000334207\n",
      "step 60, loss=0.000290471\n",
      "step 70, loss=0.000257578\n",
      "step 80, loss=0.000231478\n",
      "step 90, loss=0.000210978\n",
      "step 100, loss=0.000195365\n",
      "step 10, loss=0.00467375\n",
      "step 20, loss=0.00225064\n",
      "step 30, loss=0.00156411\n",
      "step 40, loss=0.00118614\n",
      "step 50, loss=0.000939881\n",
      "step 60, loss=0.000778253\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 70, loss=0.000665324\n",
      "step 80, loss=0.000583121\n",
      "step 90, loss=0.000511635\n",
      "step 100, loss=0.000455395\n",
      "step 10, loss=0.00696161\n",
      "step 20, loss=0.00363214\n",
      "step 30, loss=0.00247494\n",
      "step 40, loss=0.0018978\n",
      "step 50, loss=0.0015434\n",
      "step 60, loss=0.00129937\n",
      "step 70, loss=0.00112458\n",
      "step 80, loss=0.000992521\n",
      "step 90, loss=0.000886762\n",
      "step 100, loss=0.000803267\n",
      "step 10, loss=0.00503783\n",
      "step 20, loss=0.00262666\n",
      "step 30, loss=0.00170669\n",
      "step 40, loss=0.00127318\n",
      "step 50, loss=0.000990377\n",
      "step 60, loss=0.000809223\n",
      "step 70, loss=0.000679381\n",
      "step 80, loss=0.000582764\n",
      "step 90, loss=0.000501984\n",
      "step 100, loss=0.000439428\n",
      "step 10, loss=3.48085e-05\n",
      "step 20, loss=3.38549e-05\n",
      "step 30, loss=3.29012e-05\n",
      "step 40, loss=3.20668e-05\n",
      "step 50, loss=3.13516e-05\n",
      "step 60, loss=3.05171e-05\n",
      "step 70, loss=2.96827e-05\n",
      "step 80, loss=2.90866e-05\n",
      "step 90, loss=2.84906e-05\n",
      "step 100, loss=2.76562e-05\n",
      "(100, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver(var_list = theta_conv)\n",
    "saver.restore(sess,\"new_pretrained/model\")\n",
    "\n",
    "i = 0\n",
    "\n",
    "adv_imgs = None\n",
    "y_real = []\n",
    "for each in zip(x_test,y_test):\n",
    "    if sess.run(accuracy, feed_dict={x: each[0],y_: [each[1]],mode: EVAL}) == 1 and np.argmax(each[1])!=target_label:\n",
    "        adv_img = np.expand_dims(fgsm_agent.generate(sess,each[0],target_label, eps_val=0.3), axis=0)\n",
    "        if adv_imgs is None:\n",
    "            adv_imgs = adv_img\n",
    "        else:\n",
    "            adv_imgs = np.concatenate((adv_imgs,adv_img),axis = 0)\n",
    "        y_real.append(each[1])\n",
    "        i+= 1\n",
    "    if i >= 100:\n",
    "        break\n",
    "print(adv_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"adv_imgs.pkl\",'wb') as file:\n",
    "    pickle.dump(adv_imgs,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on test set: 0.0\n"
     ]
    }
   ],
   "source": [
    "FINAL_ACC=0.\n",
    "for i in range(0,100):\n",
    "    FINAL_ACC+=1/100*sess.run(accuracy, feed_dict={x: adv_imgs[i], y_: y_real[i:i+1], mode: EVAL})   \n",
    "print(\"Final accuracy on test set:\", FINAL_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final accuracy on test set: 1.0000000000000007\n"
     ]
    }
   ],
   "source": [
    "FINAL_ACC=0.\n",
    "for i in range(0,100):\n",
    "    FINAL_ACC+=1/100*sess.run(accuracy, feed_dict={x: adv_imgs[i], y_: [np.eye(10)[target_label]], mode: EVAL})   \n",
    "print(\"Final accuracy on test set:\", FINAL_ACC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 3200)\n"
     ]
    }
   ],
   "source": [
    "X = None\n",
    "for i in range(0,1):\n",
    "    if i == 0:\n",
    "        X = sess.run(flat, feed_dict={x: x_test[i*1000:(i+1)*1000], y_: y_test[i*1000:(i+1)*1000], mode: EVAL}) \n",
    "    else:\n",
    "        X = np.concatenate((X,sess.run(flat, feed_dict={x: x_test[i*1000:(i+1)*1000], y_: y_test[i*1000:(i+1)*1000], mode: EVAL})), axis = 0)\n",
    "    print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7ff160e89748>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "colors = [i*25 for i in np.argmax(y_test[0:1000], axis = 1)]\n",
    "\n",
    "embedding = TSNE(n_components=2).fit_transform(X)\n",
    "plt.scatter(embedding[:,0],embedding[:,1], c = colors )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1)\n",
      "(2, 2)\n",
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "for each in zip(np.array([1,2,3]),np.array([1,2,3])):\n",
    "    print(each)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 4 7 1 9 8 3 0 2 5]\n"
     ]
    }
   ],
   "source": [
    "targeted_label = np.array([i for i in range(10)])\n",
    "np.random.shuffle(targeted_label)\n",
    "print(targeted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
