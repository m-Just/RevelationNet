{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using real-time data augmentation.\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use variable.assign_mul if you want assignment to the variable value or 'x = x * y' if you want a new python Tensor object.\n",
      "Epoch 1/50\n",
      "391/391 [==============================] - 80s 204ms/step - loss: 2.0359 - acc: 0.2467 - val_loss: 1.7093 - val_acc: 0.3863\n",
      "Epoch 2/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 1.6714 - acc: 0.3874 - val_loss: 1.4193 - val_acc: 0.4803\n",
      "Epoch 3/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 1.4897 - acc: 0.4537 - val_loss: 1.2910 - val_acc: 0.5310\n",
      "Epoch 4/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 1.3677 - acc: 0.5036 - val_loss: 1.1605 - val_acc: 0.5826\n",
      "Epoch 5/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 1.2554 - acc: 0.5493 - val_loss: 1.0897 - val_acc: 0.6106\n",
      "Epoch 6/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 1.1597 - acc: 0.5868 - val_loss: 1.0017 - val_acc: 0.6474\n",
      "Epoch 7/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 1.0785 - acc: 0.6195 - val_loss: 0.9169 - val_acc: 0.6794\n",
      "Epoch 8/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.9995 - acc: 0.6460 - val_loss: 0.8334 - val_acc: 0.7074\n",
      "Epoch 9/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.9389 - acc: 0.6678 - val_loss: 0.8451 - val_acc: 0.7056\n",
      "Epoch 10/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.8845 - acc: 0.6882 - val_loss: 0.8031 - val_acc: 0.7241\n",
      "Epoch 11/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.8452 - acc: 0.7048 - val_loss: 0.8252 - val_acc: 0.7249\n",
      "Epoch 12/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.8105 - acc: 0.7159 - val_loss: 0.7680 - val_acc: 0.7385\n",
      "Epoch 13/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.7810 - acc: 0.7282 - val_loss: 0.7340 - val_acc: 0.7517\n",
      "Epoch 14/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.7498 - acc: 0.7400 - val_loss: 0.6735 - val_acc: 0.7630\n",
      "Epoch 15/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.7239 - acc: 0.7471 - val_loss: 0.6388 - val_acc: 0.7779\n",
      "Epoch 16/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.7089 - acc: 0.7551 - val_loss: 0.6227 - val_acc: 0.7871\n",
      "Epoch 17/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.6843 - acc: 0.7628 - val_loss: 0.6222 - val_acc: 0.7848\n",
      "Epoch 18/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.6695 - acc: 0.7683 - val_loss: 0.6347 - val_acc: 0.7890\n",
      "Epoch 19/50\n",
      "391/391 [==============================] - 26s 68ms/step - loss: 0.6588 - acc: 0.7722 - val_loss: 0.6221 - val_acc: 0.7834\n",
      "Epoch 20/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.6374 - acc: 0.7783 - val_loss: 0.6680 - val_acc: 0.7790\n",
      "Epoch 21/50\n",
      "391/391 [==============================] - 26s 65ms/step - loss: 0.6200 - acc: 0.7830 - val_loss: 0.6071 - val_acc: 0.7989\n",
      "Epoch 22/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.6121 - acc: 0.7871 - val_loss: 0.5692 - val_acc: 0.8090\n",
      "Epoch 23/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.5955 - acc: 0.7936 - val_loss: 0.5451 - val_acc: 0.8112\n",
      "Epoch 24/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.5854 - acc: 0.7950 - val_loss: 0.5605 - val_acc: 0.8090\n",
      "Epoch 25/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.5719 - acc: 0.8017 - val_loss: 0.5616 - val_acc: 0.8115\n",
      "Epoch 26/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.5653 - acc: 0.8042 - val_loss: 0.5453 - val_acc: 0.8140\n",
      "Epoch 27/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.5508 - acc: 0.8071 - val_loss: 0.5741 - val_acc: 0.8034\n",
      "Epoch 28/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.5439 - acc: 0.8095 - val_loss: 0.5756 - val_acc: 0.8119\n",
      "Epoch 29/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.5276 - acc: 0.8154 - val_loss: 0.5447 - val_acc: 0.8180\n",
      "Epoch 30/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.5186 - acc: 0.8202 - val_loss: 0.5252 - val_acc: 0.8253\n",
      "Epoch 31/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.5110 - acc: 0.8217 - val_loss: 0.5148 - val_acc: 0.8289\n",
      "Epoch 32/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.5006 - acc: 0.8271 - val_loss: 0.5164 - val_acc: 0.8301\n",
      "Epoch 33/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4997 - acc: 0.8266 - val_loss: 0.5427 - val_acc: 0.8195\n",
      "Epoch 34/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4890 - acc: 0.8301 - val_loss: 0.4999 - val_acc: 0.8325\n",
      "Epoch 35/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4811 - acc: 0.8335 - val_loss: 0.5183 - val_acc: 0.8267\n",
      "Epoch 36/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.4732 - acc: 0.8348 - val_loss: 0.5078 - val_acc: 0.8304\n",
      "Epoch 37/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4688 - acc: 0.8386 - val_loss: 0.5070 - val_acc: 0.8334\n",
      "Epoch 38/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.4616 - acc: 0.8404 - val_loss: 0.5063 - val_acc: 0.8305\n",
      "Epoch 39/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.4580 - acc: 0.8412 - val_loss: 0.5086 - val_acc: 0.8279\n",
      "Epoch 40/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.4465 - acc: 0.8452 - val_loss: 0.4824 - val_acc: 0.8392\n",
      "Epoch 41/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.4420 - acc: 0.8442 - val_loss: 0.4898 - val_acc: 0.8322\n",
      "Epoch 42/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4372 - acc: 0.8494 - val_loss: 0.4847 - val_acc: 0.8394\n",
      "Epoch 43/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.4363 - acc: 0.8477 - val_loss: 0.5215 - val_acc: 0.8286\n",
      "Epoch 44/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4271 - acc: 0.8506 - val_loss: 0.5035 - val_acc: 0.8315\n",
      "Epoch 45/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4213 - acc: 0.8541 - val_loss: 0.4904 - val_acc: 0.8393\n",
      "Epoch 46/50\n",
      "391/391 [==============================] - 26s 65ms/step - loss: 0.4186 - acc: 0.8559 - val_loss: 0.4864 - val_acc: 0.8409\n",
      "Epoch 47/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4111 - acc: 0.8566 - val_loss: 0.4893 - val_acc: 0.8400\n",
      "Epoch 48/50\n",
      "391/391 [==============================] - 26s 66ms/step - loss: 0.4021 - acc: 0.8611 - val_loss: 0.4757 - val_acc: 0.8400\n",
      "Epoch 49/50\n",
      "391/391 [==============================] - 25s 65ms/step - loss: 0.4014 - acc: 0.8610 - val_loss: 0.4914 - val_acc: 0.8413\n",
      "Epoch 50/50\n",
      "391/391 [==============================] - 26s 67ms/step - loss: 0.3950 - acc: 0.8627 - val_loss: 0.5049 - val_acc: 0.8341\n",
      "Saved trained model at /home/pdimage/notebooks/dynamic_network/keras/saved_models/keras_cifar10_trained_model.h5 \n",
      "10000/10000 [==============================] - 2s 167us/step\n",
      "Test loss: 0.5048797336578369\n",
      "Test accuracy: 0.8341\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import LeakyReLU, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 50\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Convert class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),\n",
    "                        input_shape=(32, 32, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# initiate RMSprop optimizer\n",
    "opt = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Let's train the model using RMSprop\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "if not data_augmentation:\n",
    "    print('Not using data augmentation.')\n",
    "    model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)\n",
    "else:\n",
    "    print('Using real-time data augmentation.')\n",
    "    # This will do preprocessing and realtime data augmentation:\n",
    "    datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "    # Compute quantities required for feature-wise normalization\n",
    "    # (std, mean, and principal components if ZCA whitening is applied).\n",
    "    datagen.fit(x_train)\n",
    "\n",
    "    # Fit the model on the batches generated by datagen.flow().\n",
    "    model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs,\n",
    "                        validation_data=(x_test, y_test),\n",
    "                        workers=4)\n",
    "\n",
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)\n",
    "\n",
    "\n",
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../tf/pretrained/model'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.backend import get_session\n",
    "import os\n",
    "if not os.path.exists('../tf/pretrained/'):\n",
    "    os.makedirs('../tf/pretrained/')\n",
    "sess = get_session()\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess,'../tf/pretrained/model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
